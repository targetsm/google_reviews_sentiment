{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0150c5f",
   "metadata": {},
   "source": [
    "# Cohaga DS Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da765fe",
   "metadata": {},
   "source": [
    "## Data import and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4001df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a99c99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>google_maps_profile_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>source_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>624932</td>\n",
       "      <td>6386691</td>\n",
       "      <td>Sehr leckeres Essen... Personal ist zudem sehr...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624932</td>\n",
       "      <td>6386692</td>\n",
       "      <td>Auf 800 m auf der Sonnenterrasse Heiden treffe...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>624932</td>\n",
       "      <td>6386693</td>\n",
       "      <td>Sehr feines Libanesisches Essen. Ein Hauch vom...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>624932</td>\n",
       "      <td>6386694</td>\n",
       "      <td>Gutes Essen</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>624932</td>\n",
       "      <td>6386695</td>\n",
       "      <td>Toller Geheimtipp.\\nNicht viel Platz dafür ein...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>151741</td>\n",
       "      <td>3027281</td>\n",
       "      <td>Pas assez d'intimité quand on est seul sinon m...</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>151741</td>\n",
       "      <td>3027284</td>\n",
       "      <td>Accueil tres bien\\nService souriant\\nTres prop...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>151741</td>\n",
       "      <td>3027288</td>\n",
       "      <td>La cuisine d'Alain Meystre est toujours aussi ...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>151741</td>\n",
       "      <td>3027291</td>\n",
       "      <td>Nous étions côte brasserie,pour un  menu surpr...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>151741</td>\n",
       "      <td>3027293</td>\n",
       "      <td>Très bon accueil et très bonne cuisine</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      google_maps_profile_id  review_id   \n",
       "0                     624932    6386691  \\\n",
       "1                     624932    6386692   \n",
       "2                     624932    6386693   \n",
       "3                     624932    6386694   \n",
       "4                     624932    6386695   \n",
       "...                      ...        ...   \n",
       "9995                  151741    3027281   \n",
       "9996                  151741    3027284   \n",
       "9997                  151741    3027288   \n",
       "9998                  151741    3027291   \n",
       "9999                  151741    3027293   \n",
       "\n",
       "                                                 review  rating   \n",
       "0     Sehr leckeres Essen... Personal ist zudem sehr...       5  \\\n",
       "1     Auf 800 m auf der Sonnenterrasse Heiden treffe...       5   \n",
       "2     Sehr feines Libanesisches Essen. Ein Hauch vom...       5   \n",
       "3                                           Gutes Essen       5   \n",
       "4     Toller Geheimtipp.\\nNicht viel Platz dafür ein...       5   \n",
       "...                                                 ...     ...   \n",
       "9995  Pas assez d'intimité quand on est seul sinon m...       3   \n",
       "9996  Accueil tres bien\\nService souriant\\nTres prop...       5   \n",
       "9997  La cuisine d'Alain Meystre est toujours aussi ...       5   \n",
       "9998  Nous étions côte brasserie,pour un  menu surpr...       5   \n",
       "9999             Très bon accueil et très bonne cuisine       4   \n",
       "\n",
       "                                             source_url  \n",
       "0     https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "1     https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "2     https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "3     https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "4     https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "...                                                 ...  \n",
       "9995  https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "9996  https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "9997  https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "9998  https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "9999  https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"data/task_1_google_maps_comments.csv\")\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd85efba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   google_maps_profile_id  10000 non-null  int64 \n",
      " 1   review                  10000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "sentences = data_df.loc[:, ['google_maps_profile_id', 'review']]\n",
    "sentences.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "870e3688",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating\n",
      "5    6986\n",
      "4    1591\n",
      "1     644\n",
      "3     461\n",
      "2     318\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(list(map(len, sentences.review)), bins=20, log=True)\n",
    "\n",
    "print(data_df.rating.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e832c41",
   "metadata": {},
   "source": [
    "### Check languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42faeb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "model = fasttext.load_model('models/lid.176.bin')\n",
    "lang_list = [model.predict(review.replace('\\n', ' '), k=1)[0][0] for review in sentences.review]\n",
    "lang_df = sentences.copy()\n",
    "lang_df['language'] = lang_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1e2de99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__vi Un saluto a Giovà :D\n",
      "__label__he מקום מעולה לעצירה מול נוף מטורף.\n",
      "__label__la Tiptopp👌😍\n",
      "__label__th บรรยากาศเยี่ยม อาหารอร่อยมากๆๆๆ\n",
      "__label__el Είναι τέλειο. 😍\n",
      "__label__ca Vistes impressionants. Bon menjar i bon servei\n",
      "__label__fr Sehr lecker\n",
      "__label__pl Cudny widok, pyszne szwajcarskie piwko i winko\n",
      "__label__sh Tip top\n",
      "__label__oc Mmmmmh...\n",
      "__label__tr Cok basarili keyifli lezzetli manzarasi harika bir restorant güleryüzlü servis\n",
      "__label__it Panorama stupendo, servizio cortese e professionale . La cucina è curata e i piatti appagano l'occhio e la gola!!!!! Ci ritornerò quanto prima!!!\n",
      "__label__mn Super . Сайхан мэдрэмж үхрийн мах адууны мах загас бүгд орчин сайхан урлагийн бүтээл үхэр мандтугай\n",
      "__label__nl Top!\n",
      "__label__ko 아름다운경치에서차한잔\n",
      "__label__sr Izuzetno čisto, izuzetno ljubazno osoblje, izuzetno sveža i ukusna hrana, domaćinski u pravom smislu te reči.\n",
      "Lidija Stefanović, Waltenschwil\n",
      "__label__es Muy recomendable 👌 👍\n",
      "__label__uk Смачно, швидко, привітно\n",
      "__label__nn Perfekt 👍👍👍\n",
      "__label__hr Sasvim pristojno. Omjer cijene i kvalitete.\n",
      "__label__br zebra burger>\n",
      "__label__de Sehr leckeres Essen... Personal ist zudem sehr freundlich.\n",
      "__label__ia A repetir a visita! ❤️✌️✌️\n",
      "__label__zh 😀😀😀\n",
      "__label__ar مكان يستحق الزيارة الموقع مقابل البحيرة\n",
      "__label__id Tiptop\n",
      "__label__ru Вид с ресторана, завораживает. Кухня тоже отличная, швейцарская.\n",
      "Цены так же, не самые большие в Швейцарии.\n",
      "__label__hu Szép hangulatos helyen, finom ételek. Maximális vendéglátás.\n",
      "__label__pt Atendimento impecável e excelente variedade de comida libanesa.\n",
      "__label__bn Mega fein gsi\n",
      "__label__ja スネガから歩いて往復しましたが、坂がとんでもなくきつかったです笑　ビールは6CHF😊　清潔で雰囲気が良い素敵なレストランでした！\n",
      "__label__sk Pekná miestna reštaurácia v alpskom štýle. Pizza super.Ceny samozrejme na úrovni švajčiarskych Álp 😁😁\n",
      "__label__da Hyggelig after ski med flott beliggenhet. Akkurat når du kommer ned fra en mega-lang nedkjøling fra fjellet og bena er passe gele. Da er det godt med en øl 😊\n",
      "__label__sv 👌\n",
      "__label__eu S beste vo de wält 😘😍\n",
      "__label__ceb 😀😄😄😄\n",
      "__label__ro Patronul foarte rau\n",
      "__label__nds Sehr leckeres Essen!😀❤️\n",
      "__label__sl Guet gsiii\n",
      "__label__fi Terassi mahtavien vuorten vieressä ja palvelu great!!😀\n",
      "__label__gl Genial:)\n",
      "__label__bg Вкусно.\n",
      "__label__als Dankä viilmal für dii früündlich bedienig... Esch schön gsi bi öui 😏\n",
      "__label__eo Paradiso puro\n",
      "__label__no Placut\n",
      "__label__en Great food and nice friendly familiar service.\n",
      "__label__cs Vše bylo výborné\n",
      "__label__ast Wunderbares Ostermenüe.\n",
      "__label__ms Guter Kebap\n",
      "__label__fa خوب بود\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "language\n",
       "__label__de     5808\n",
       "__label__en     1728\n",
       "__label__fr      991\n",
       "__label__it      951\n",
       "__label__es       99\n",
       "__label__nl       62\n",
       "__label__pt       52\n",
       "__label__ar       51\n",
       "__label__pl       29\n",
       "__label__tr       24\n",
       "__label__als      22\n",
       "__label__ko       20\n",
       "__label__sv       17\n",
       "__label__ru       16\n",
       "__label__zh       15\n",
       "__label__ja       14\n",
       "__label__hu        8\n",
       "__label__da        7\n",
       "__label__cs        6\n",
       "__label__fi        6\n",
       "__label__ro        6\n",
       "__label__sl        5\n",
       "__label__ca        5\n",
       "__label__ceb       5\n",
       "__label__no        5\n",
       "__label__vi        4\n",
       "__label__bg        4\n",
       "__label__id        4\n",
       "__label__uk        3\n",
       "__label__eo        3\n",
       "__label__he        3\n",
       "__label__hr        3\n",
       "__label__sr        2\n",
       "__label__oc        2\n",
       "__label__th        2\n",
       "__label__ms        2\n",
       "__label__el        2\n",
       "__label__sk        2\n",
       "__label__fa        1\n",
       "__label__br        1\n",
       "__label__ast       1\n",
       "__label__nds       1\n",
       "__label__gl        1\n",
       "__label__mn        1\n",
       "__label__nn        1\n",
       "__label__eu        1\n",
       "__label__la        1\n",
       "__label__ia        1\n",
       "__label__bn        1\n",
       "__label__sh        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for l in set(lang_list):\n",
    "    print(l, lang_df[lang_df.language == l].iloc[0].review)\n",
    "lang_df.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65cd385",
   "metadata": {},
   "source": [
    "### Self-rated Gold-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee0f4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df_data = data_df.iloc[::100].copy()\n",
    "gold_df_data.to_csv('data/gold.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e648fe34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>google_maps_profile_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>food_sentiment</th>\n",
       "      <th>service_sentiment</th>\n",
       "      <th>atmosphere_sentiment</th>\n",
       "      <th>rating</th>\n",
       "      <th>source_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>624932</td>\n",
       "      <td>6386691</td>\n",
       "      <td>Sehr leckeres Essen... Personal ist zudem sehr...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>579787</td>\n",
       "      <td>2562311</td>\n",
       "      <td>Ich war mit meiner Freundin in der meeega schõ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>579787</td>\n",
       "      <td>2562480</td>\n",
       "      <td>Wir waren Mitte Januar im Restaurant,  also 2-...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>579787</td>\n",
       "      <td>2562661</td>\n",
       "      <td>Preis - Leistung stimmte für nicht nicht!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>579787</td>\n",
       "      <td>2562835</td>\n",
       "      <td>Die Gerstensuppe war für meinen Geschmack ein ...</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>297560</td>\n",
       "      <td>1038882</td>\n",
       "      <td>Obercool immer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>297560</td>\n",
       "      <td>1039102</td>\n",
       "      <td>Die besten Burger bekomt mann im ACE Cafe 🤘🤙👌</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>297560</td>\n",
       "      <td>1039357</td>\n",
       "      <td>Not quite the original, but let's see</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>297560</td>\n",
       "      <td>1039582</td>\n",
       "      <td>Hoi Dani und Team.\\nWill auch mal meinen Senf ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>151741</td>\n",
       "      <td>3027100</td>\n",
       "      <td>Des plats délicieux et un accueil chaleureux e...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.google.com/maps/reviews/data=!4m8!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    google_maps_profile_id  review_id   \n",
       "0                   624932    6386691  \\\n",
       "1                   579787    2562311   \n",
       "2                   579787    2562480   \n",
       "3                   579787    2562661   \n",
       "4                   579787    2562835   \n",
       "..                     ...        ...   \n",
       "95                  297560    1038882   \n",
       "96                  297560    1039102   \n",
       "97                  297560    1039357   \n",
       "98                  297560    1039582   \n",
       "99                  151741    3027100   \n",
       "\n",
       "                                               review  food_sentiment   \n",
       "0   Sehr leckeres Essen... Personal ist zudem sehr...             0.9  \\\n",
       "1   Ich war mit meiner Freundin in der meeega schõ...             0.5   \n",
       "2   Wir waren Mitte Januar im Restaurant,  also 2-...             0.4   \n",
       "3           Preis - Leistung stimmte für nicht nicht!             NaN   \n",
       "4   Die Gerstensuppe war für meinen Geschmack ein ...            -0.2   \n",
       "..                                                ...             ...   \n",
       "95                                     Obercool immer             NaN   \n",
       "96      Die besten Burger bekomt mann im ACE Cafe 🤘🤙👌             0.6   \n",
       "97              Not quite the original, but let's see             NaN   \n",
       "98  Hoi Dani und Team.\\nWill auch mal meinen Senf ...             NaN   \n",
       "99  Des plats délicieux et un accueil chaleureux e...             0.6   \n",
       "\n",
       "    service_sentiment  atmosphere_sentiment  rating   \n",
       "0                 0.6                   NaN       5  \\\n",
       "1                 0.8                   0.6       5   \n",
       "2                 0.6                   0.3       4   \n",
       "3                 NaN                   NaN       2   \n",
       "4                 NaN                   0.8       4   \n",
       "..                ...                   ...     ...   \n",
       "95                NaN                   NaN       5   \n",
       "96                NaN                   NaN       5   \n",
       "97                NaN                   NaN       3   \n",
       "98                NaN                   NaN       5   \n",
       "99                0.7                   NaN       5   \n",
       "\n",
       "                                           source_url  \n",
       "0   https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "1   https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "2   https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "3   https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "4   https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "..                                                ...  \n",
       "95  https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "96  https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "97  https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "98  https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "99  https://www.google.com/maps/reviews/data=!4m8!...  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df_full = pd.read_csv(\"data/gold_annotated.csv\")\n",
    "gold_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a903d30c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>food_sentiment</th>\n",
       "      <th>service_sentiment</th>\n",
       "      <th>atmosphere_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sehr leckeres Essen... Personal ist zudem sehr...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ich war mit meiner Freundin in der meeega schõ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wir waren Mitte Januar im Restaurant,  also 2-...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Preis - Leistung stimmte für nicht nicht!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Die Gerstensuppe war für meinen Geschmack ein ...</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Obercool immer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Die besten Burger bekomt mann im ACE Cafe 🤘🤙👌</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Not quite the original, but let's see</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Hoi Dani und Team.\\nWill auch mal meinen Senf ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Des plats délicieux et un accueil chaleureux e...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  food_sentiment   \n",
       "0   Sehr leckeres Essen... Personal ist zudem sehr...             0.9  \\\n",
       "1   Ich war mit meiner Freundin in der meeega schõ...             0.5   \n",
       "2   Wir waren Mitte Januar im Restaurant,  also 2-...             0.4   \n",
       "3           Preis - Leistung stimmte für nicht nicht!             NaN   \n",
       "4   Die Gerstensuppe war für meinen Geschmack ein ...            -0.2   \n",
       "..                                                ...             ...   \n",
       "95                                     Obercool immer             NaN   \n",
       "96      Die besten Burger bekomt mann im ACE Cafe 🤘🤙👌             0.6   \n",
       "97              Not quite the original, but let's see             NaN   \n",
       "98  Hoi Dani und Team.\\nWill auch mal meinen Senf ...             NaN   \n",
       "99  Des plats délicieux et un accueil chaleureux e...             0.6   \n",
       "\n",
       "    service_sentiment  atmosphere_sentiment  \n",
       "0                 0.6                   NaN  \n",
       "1                 0.8                   0.6  \n",
       "2                 0.6                   0.3  \n",
       "3                 NaN                   NaN  \n",
       "4                 NaN                   0.8  \n",
       "..                ...                   ...  \n",
       "95                NaN                   NaN  \n",
       "96                NaN                   NaN  \n",
       "97                NaN                   NaN  \n",
       "98                NaN                   NaN  \n",
       "99                0.7                   NaN  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df = gold_df_full[['review', 'food_sentiment', 'service_sentiment', 'atmosphere_sentiment']]\n",
    "gold_df\n",
    "\n",
    "# TODO:\n",
    "# - same distribution of languages or equal distribution of languages\n",
    "# - equal distribution of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "045ebcf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  food_sentiment   \n",
      "0  Sehr leckeres Essen... Personal ist zudem sehr...             0.9  \\\n",
      "2  Wir waren Mitte Januar im Restaurant,  also 2-...             0.4   \n",
      "4  Die Gerstensuppe war für meinen Geschmack ein ...            -0.2   \n",
      "6            Sehr unfreundliches Personal!! Schade .             NaN   \n",
      "8  Best meal of our entire week vacation. Incredi...             1.0   \n",
      "\n",
      "   service_sentiment  atmosphere_sentiment  \n",
      "0                0.6                   NaN  \n",
      "2                0.6                   0.3  \n",
      "4                NaN                   0.8  \n",
      "6               -0.8                   NaN  \n",
      "8                NaN                   NaN  \n",
      "                                              review  food_sentiment   \n",
      "1  Ich war mit meiner Freundin in der meeega schõ...             0.5  \\\n",
      "3          Preis - Leistung stimmte für nicht nicht!             NaN   \n",
      "5  Tolle Aussicht, Käse Spätzle waren super, etwa...             0.6   \n",
      "7  Einfach super! Das Ambiente, die Bedienung, di...             0.8   \n",
      "9                                            Beschte             NaN   \n",
      "\n",
      "   service_sentiment  atmosphere_sentiment  \n",
      "1                0.8                   0.6  \n",
      "3                NaN                   NaN  \n",
      "5               -0.1                   0.5  \n",
      "7                0.7                   0.7  \n",
      "9                NaN                   NaN  \n"
     ]
    }
   ],
   "source": [
    "# Split data into dev and test\n",
    "gold_df_dev = gold_df[::2]\n",
    "gold_df_test = gold_df[1::2] \n",
    "print(gold_df_dev.head())\n",
    "print(gold_df_test.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d4a7a5",
   "metadata": {},
   "source": [
    "### Public Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "285f7825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSA16_Restaurants_Train_English_SB2.xml\n",
      "restaurants_dutch_training_textlevel.xml\n",
      "restaurant_tain_text_level_final.xml\n",
      "SemEval-2016ABSA Restaurants-Spanish_Train_Subtask2.xml\n",
      "se16_ru_rest_train_task2.xml\n",
      "                                                 review food_sentiment   \n",
      "0     Judging from previous posts this used to be a ...       negative  \\\n",
      "1     I have eaten at Saul, many times, the food is ...       positive   \n",
      "2     Went on a 3 day oyster binge, with Fish bringi...       positive   \n",
      "3     Every time in New York I make it a point to vi...       positive   \n",
      "4     We ate outside at Haru's Sake bar because Haru...       positive   \n",
      "...                                                 ...            ...   \n",
      "1859  Сегодня были компанией из 4х человек, были уже...       positive   \n",
      "1860  Вчера отмечали день рождения в ресторане, сход...       positive   \n",
      "1861  Очень приятное уютное местечко. Хороший ценник...       conflict   \n",
      "1862  В прошлую субботу посетили с друзьями это заве...       positive   \n",
      "1863  Зашли в\"аппетит\" случайно. Не смотря на то,что...       positive   \n",
      "\n",
      "     service_sentiment atmosphere_sentiment  \n",
      "0             negative                 None  \n",
      "1                 None                 None  \n",
      "2             positive                 None  \n",
      "3             positive             positive  \n",
      "4             positive                 None  \n",
      "...                ...                  ...  \n",
      "1859          positive             conflict  \n",
      "1860          positive             positive  \n",
      "1861          conflict             conflict  \n",
      "1862          positive             conflict  \n",
      "1863          positive                 None  \n",
      "\n",
      "[1864 rows x 4 columns]\n",
      "ABSA16_Restaurants_Train_SB1_v2.xml\n",
      "restaurants_dutch_training.xml\n",
      "reviews.xml\n",
      "SemEval-2016ABSA Restaurants-Spanish_Train_Subtask1.xml\n",
      "se16_ru_rest_train.xml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>food_sentiment</th>\n",
       "      <th>service_sentiment</th>\n",
       "      <th>atmosphere_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La atención al cliente no es la correcta y la ...</td>\n",
       "      <td>None</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hemos ido a cenar y la verdad es que nos ha en...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Büyük porsiyonlar anca bir normal porsiyon old...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great sushi experience. Nice value. Unique app...</td>\n",
       "      <td>positive</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fethipaşa korusunun içinde bulunan manzarasına...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>Kendi biralarını çoğunluğun aksine pek beğenme...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>Kuru fasülye için tercih etmek gerek diye düsü...</td>\n",
       "      <td>positive</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>Estuvimos hace poco mi pareja y yo comiendo y ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>Terrible would be a compliment! The service le...</td>\n",
       "      <td>None</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>La cena nos ha gustado mucho, tanto el menú co...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3539 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review food_sentiment   \n",
       "0     La atención al cliente no es la correcta y la ...           None  \\\n",
       "1     Hemos ido a cenar y la verdad es que nos ha en...       positive   \n",
       "2     Büyük porsiyonlar anca bir normal porsiyon old...           None   \n",
       "3     Great sushi experience. Nice value. Unique app...       positive   \n",
       "4     Fethipaşa korusunun içinde bulunan manzarasına...           None   \n",
       "...                                                 ...            ...   \n",
       "3534  Kendi biralarını çoğunluğun aksine pek beğenme...           None   \n",
       "3535  Kuru fasülye için tercih etmek gerek diye düsü...       positive   \n",
       "3536  Estuvimos hace poco mi pareja y yo comiendo y ...       positive   \n",
       "3537  Terrible would be a compliment! The service le...           None   \n",
       "3538  La cena nos ha gustado mucho, tanto el menú co...       positive   \n",
       "\n",
       "     service_sentiment atmosphere_sentiment  \n",
       "0             negative                 None  \n",
       "1             positive             positive  \n",
       "2                 None                 None  \n",
       "3                 None                 None  \n",
       "4                 None             positive  \n",
       "...                ...                  ...  \n",
       "3534              None             negative  \n",
       "3535              None                 None  \n",
       "3536          positive             positive  \n",
       "3537          negative                 None  \n",
       "3538          positive                 None  \n",
       "\n",
       "[3539 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xmltodict\n",
    "\n",
    "semval_df = pd.DataFrame(columns=['review','food_sentiment','service_sentiment', 'atmosphere_sentiment'])\n",
    "\n",
    "\n",
    "for file in ['ABSA16_Restaurants_Train_English_SB2.xml', 'restaurants_dutch_training_textlevel.xml', 'restaurant_tain_text_level_final.xml', 'SemEval-2016ABSA Restaurants-Spanish_Train_Subtask2.xml', 'se16_ru_rest_train_task2.xml']:\n",
    "    with open(f'data/semeval/{file}') as f:\n",
    "       xml_string = f.read()\n",
    "    print(file)\n",
    "    xml_dict = xmltodict.parse(xml_string)\n",
    "    Reviews = xml_dict['Reviews']['Review']\n",
    "    for review in Reviews:\n",
    "        sentence_concat = ''\n",
    "        #print(review)\n",
    "        if isinstance(review['sentences']['sentence'], dict):\n",
    "            sentence_concat += review['sentences']['sentence']['text'] + \" \"\n",
    "        else:\n",
    "            for sentence in review['sentences']['sentence']:\n",
    "                #print(sentence)\n",
    "                sentence_concat += sentence['text'] + \" \"\n",
    "        sent_food = None\n",
    "        sent_service = None\n",
    "        sent_atmosphere = None\n",
    "        #print('review:', review)\n",
    "        if (review['Opinions'] != None):\n",
    "            if isinstance(review['Opinions']['Opinion'], dict):\n",
    "                opinion = review['Opinions']['Opinion']\n",
    "                if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                    sent_food = opinion['@polarity']\n",
    "                elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                    sent_service = opinion['@polarity']\n",
    "                elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                    sent_atmosphere = opinion['@polarity']\n",
    "            else:\n",
    "                for opinion in review['Opinions']['Opinion']:\n",
    "                    if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                        sent_food = opinion['@polarity']\n",
    "                    elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                        sent_service = opinion['@polarity']\n",
    "                    elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                        sent_atmosphere = opinion['@polarity']\n",
    "        semval_df.loc[len(semval_df)] = [sentence_concat, sent_food, sent_service, sent_atmosphere]\n",
    "print(semval_df)\n",
    "\n",
    "\n",
    "for file in ['ABSA16_Restaurants_Train_SB1_v2.xml', 'restaurants_dutch_training.xml', 'reviews.xml', 'SemEval-2016ABSA Restaurants-Spanish_Train_Subtask1.xml', 'se16_ru_rest_train.xml']:\n",
    "    with open(f'data/semeval/{file}') as f:\n",
    "       xml_string = f.read()\n",
    "    print(file)\n",
    "    xml_dict = xmltodict.parse(xml_string)\n",
    "    Reviews = xml_dict['Reviews']['Review']\n",
    "    for review in Reviews:\n",
    "        sentence_concat = ''\n",
    "        if isinstance(review['sentences']['sentence'], dict):\n",
    "            sentence_concat += review['sentences']['sentence']['text'] + \" \"\n",
    "        else:\n",
    "            for sentence in review['sentences']['sentence']:\n",
    "                sentence_concat += sentence['text'] + \" \"\n",
    "                sent_food = None\n",
    "                sent_service = None\n",
    "                sent_atmosphere = None\n",
    "                if ('Opinions' in sentence) and (sentence['Opinions'] != None):\n",
    "                    if isinstance(sentence['Opinions']['Opinion'], dict):\n",
    "                        opinion = sentence['Opinions']['Opinion']\n",
    "                        if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                            sent_food = opinion['@polarity']\n",
    "                        elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                            sent_service = opinion['@polarity']\n",
    "                        elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                            sent_atmosphere = opinion['@polarity']\n",
    "                    else:\n",
    "                        for opinion in sentence['Opinions']['Opinion']:\n",
    "                            if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                                sent_food = opinion['@polarity']\n",
    "                            elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                                sent_service = opinion['@polarity']\n",
    "                            elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                                sent_atmosphere = opinion['@polarity']\n",
    "            semval_df.loc[len(semval_df)] = [sentence_concat, sent_food, sent_service, sent_atmosphere]\n",
    "\n",
    "# randomly shuffle data\n",
    "semval_df = semval_df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "semval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f81a68ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_sentiment\n",
      "None        1722\n",
      "positive    1370\n",
      "negative     275\n",
      "neutral       88\n",
      "conflict      84\n",
      "Name: count, dtype: int64\n",
      "service_sentiment\n",
      "None        2007\n",
      "positive     961\n",
      "negative     458\n",
      "conflict      65\n",
      "neutral       48\n",
      "Name: count, dtype: int64\n",
      "atmosphere_sentiment\n",
      "None        2402\n",
      "positive     831\n",
      "negative     192\n",
      "conflict      71\n",
      "neutral       43\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(semval_df['food_sentiment'].value_counts(dropna=False))\n",
    "print(semval_df['service_sentiment'].value_counts(dropna=False))\n",
    "print(semval_df['atmosphere_sentiment'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "103c2e65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN_REST_SB2_TEST.xml.gold\n",
      "DU_REST_SB2_TEST.xml.gold\n",
      "RU_REST_SB2_TEST.xml.gold\n",
      "SP_REST_SB2_TEST.xml.gold\n",
      "TU_REST_SB2_TEST.xml.gold\n",
      "<bound method DataFrame.info of                                                 review food_sentiment   \n",
      "0    Yum! Serves really good sushi. Not the biggest...       positive  \\\n",
      "1    No Comparison – I can't say enough about this ...       positive   \n",
      "2    Snotty Attitude – We were treated very rudely ...           None   \n",
      "3    Good food! – We love breakfast food. This is a...       positive   \n",
      "4    Overrated – I was highly disappointed in the f...       negative   \n",
      "..                                                 ...            ...   \n",
      "595  Kebap ve Et restoranları aleminde sıkça karşıl...       positive   \n",
      "596  Manzara süper,yemekler fena değil ama porsiyon...        neutral   \n",
      "597  çok sıcak çok kalabalık denizden koku geliyor ...       negative   \n",
      "598  Çalışanlar kesinlikle çok nezih. Çayı da güzel...       positive   \n",
      "599  Deniz kenarında olan bütün mekanların aurası b...       positive   \n",
      "\n",
      "    service_sentiment atmosphere_sentiment  \n",
      "0                None                 None  \n",
      "1            positive                 None  \n",
      "2            negative                 None  \n",
      "3            positive                 None  \n",
      "4                None             positive  \n",
      "..                ...                  ...  \n",
      "595              None             positive  \n",
      "596              None             positive  \n",
      "597          negative             negative  \n",
      "598          positive                 None  \n",
      "599              None             positive  \n",
      "\n",
      "[600 rows x 4 columns]>\n",
      "EN_REST_SB1_TEST.xml.gold\n",
      "DU_REST_SB1_TEST.xml.gold\n",
      "ABSA16FR_Restaurants_Gold-withcontent.xml\n",
      "RU_REST_SB1_TEST.xml.gold\n",
      "SP_REST_SB1_TEST.xml.gold\n",
      "TU_REST_SB1_TEST.xml.gold\n",
      "                                                 review food_sentiment   \n",
      "0     Buff, No se donde empezar! El Servicio y la at...           None  \\\n",
      "1     Me gusto mucho el menú. Para no quedarse con h...           None   \n",
      "2     Gracias por tu crónica, me ha sido de gran ayu...           None   \n",
      "3     Muy bueno, calidad-precio. Pedimos menu de cal...       positive   \n",
      "4     Brugge is een mooie stad. De spareribs waren l...           None   \n",
      "...                                                 ...            ...   \n",
      "1241  En nog heel lekker gegeten ook! We volgden de ...       positive   \n",
      "1242  Занесло нас сюда огромное желание поесть мясо,...           None   \n",
      "1243  Un buen restaurante relación calidad-precio mu...           None   \n",
      "1244  Побывали с друзьями в Малевиче. Слухов было мн...       conflict   \n",
      "1245  Un restaurante como la copa de un pino. Gran d...       positive   \n",
      "\n",
      "     service_sentiment atmosphere_sentiment  \n",
      "0             positive                 None  \n",
      "1                 None                 None  \n",
      "2                 None                 None  \n",
      "3             positive             positive  \n",
      "4             positive                 None  \n",
      "...                ...                  ...  \n",
      "1241              None                 None  \n",
      "1242          positive                 None  \n",
      "1243              None                 None  \n",
      "1244          negative             positive  \n",
      "1245              None             positive  \n",
      "\n",
      "[1246 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "\n",
    "import xmltodict\n",
    "\n",
    "\n",
    "semval_test_df = pd.DataFrame(columns=['review','food_sentiment','service_sentiment', 'atmosphere_sentiment'])\n",
    "\n",
    "for file in ['EN_REST_SB2_TEST.xml.gold', 'DU_REST_SB2_TEST.xml.gold', 'RU_REST_SB2_TEST.xml.gold', 'SP_REST_SB2_TEST.xml.gold', 'TU_REST_SB2_TEST.xml.gold']:\n",
    "    with open(f'data/semeval/test/{file}') as f:\n",
    "       xml_string = f.read()\n",
    "    print(file)\n",
    "    xml_dict = xmltodict.parse(xml_string)\n",
    "    Reviews = xml_dict['Reviews']['Review']\n",
    "    for review in Reviews:\n",
    "        sentence_concat = ''\n",
    "        if isinstance(review['sentences']['sentence'], dict):\n",
    "            sentence_concat += review['sentences']['sentence']['text'] + \" \"\n",
    "        else:\n",
    "            for sentence in review['sentences']['sentence']:\n",
    "                sentence_concat += sentence['text'] + \" \"\n",
    "        sent_food = None\n",
    "        sent_service = None\n",
    "        sent_atmosphere = None\n",
    "        if (review['Opinions'] != None):\n",
    "            if isinstance(review['Opinions']['Opinion'], dict):\n",
    "                opinion = review['Opinions']['Opinion']\n",
    "                if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                    sent_food = opinion['@polarity']\n",
    "                elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                    sent_service = opinion['@polarity']\n",
    "                elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                    sent_atmosphere = opinion['@polarity']\n",
    "            else:\n",
    "                for opinion in review['Opinions']['Opinion']:\n",
    "                    if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                        sent_food = opinion['@polarity']\n",
    "                    elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                        sent_service = opinion['@polarity']\n",
    "                    elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                        sent_atmosphere = opinion['@polarity']\n",
    "        semval_test_df.loc[len(semval_test_df)] = [sentence_concat, sent_food, sent_service, sent_atmosphere]\n",
    "print(semval_test_df.info)\n",
    "\n",
    "for file in ['EN_REST_SB1_TEST.xml.gold', 'DU_REST_SB1_TEST.xml.gold', 'ABSA16FR_Restaurants_Gold-withcontent.xml', 'RU_REST_SB1_TEST.xml.gold', 'SP_REST_SB1_TEST.xml.gold', 'TU_REST_SB1_TEST.xml.gold']:\n",
    "    with open(f'data/semeval/test/{file}') as f:\n",
    "       xml_string = f.read()\n",
    "    print(file)\n",
    "    xml_dict = xmltodict.parse(xml_string)\n",
    "    Reviews = xml_dict['Reviews']['Review']\n",
    "    for review in Reviews:\n",
    "        sentence_concat = ''\n",
    "        if isinstance(review['sentences']['sentence'], dict):\n",
    "            sentence_concat += review['sentences']['sentence']['text'] + \" \"\n",
    "        else:\n",
    "            for sentence in review['sentences']['sentence']:\n",
    "                if sentence['text'] != None:\n",
    "                    sentence_concat += sentence['text'] + \" \"\n",
    "                    sent_food = None\n",
    "                    sent_service = None\n",
    "                    sent_atmosphere = None\n",
    "                    if ('Opinions' in sentence) and (sentence['Opinions'] != None):\n",
    "                        if isinstance(sentence['Opinions']['Opinion'], dict):\n",
    "                            opinion = sentence['Opinions']['Opinion']\n",
    "                            if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                                sent_food = opinion['@polarity']\n",
    "                            elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                                sent_service = opinion['@polarity']\n",
    "                            elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                                sent_atmosphere = opinion['@polarity']\n",
    "                        else:\n",
    "                            for opinion in sentence['Opinions']['Opinion']:\n",
    "                                if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                                    sent_food = opinion['@polarity']\n",
    "                                elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                                    sent_service = opinion['@polarity']\n",
    "                                elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                                    sent_atmosphere = opinion['@polarity']\n",
    "            semval_test_df.loc[len(semval_test_df)] = [sentence_concat, sent_food, sent_service, sent_atmosphere]\n",
    "\n",
    "# randomly shuffle data\n",
    "semval_test_df = semval_test_df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "print(semval_test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "370de286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_sentiment\n",
      "None        657\n",
      "positive    453\n",
      "negative     81\n",
      "conflict     30\n",
      "neutral      25\n",
      "Name: count, dtype: int64\n",
      "service_sentiment\n",
      "None        748\n",
      "positive    333\n",
      "negative    133\n",
      "conflict     17\n",
      "neutral      15\n",
      "Name: count, dtype: int64\n",
      "atmosphere_sentiment\n",
      "None        907\n",
      "positive    234\n",
      "negative     69\n",
      "conflict     24\n",
      "neutral      12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(semval_test_df['food_sentiment'].value_counts(dropna=False))\n",
    "print(semval_test_df['service_sentiment'].value_counts(dropna=False))\n",
    "print(semval_test_df['atmosphere_sentiment'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f42da1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 review food_sentiment   \n",
      "0     La atención al cliente no es la correcta y la ...           None  \\\n",
      "1     Hemos ido a cenar y la verdad es que nos ha en...       positive   \n",
      "2     Büyük porsiyonlar anca bir normal porsiyon old...           None   \n",
      "3     Great sushi experience. Nice value. Unique app...       positive   \n",
      "4     Fethipaşa korusunun içinde bulunan manzarasına...           None   \n",
      "...                                                 ...            ...   \n",
      "4656  En nog heel lekker gegeten ook! We volgden de ...       positive   \n",
      "4657  Занесло нас сюда огромное желание поесть мясо,...           None   \n",
      "4658  Un buen restaurante relación calidad-precio mu...           None   \n",
      "4659  Побывали с друзьями в Малевиче. Слухов было мн...       conflict   \n",
      "4660  Un restaurante como la copa de un pino. Gran d...       positive   \n",
      "\n",
      "     service_sentiment atmosphere_sentiment  \n",
      "0             negative                 None  \n",
      "1             positive             positive  \n",
      "2                 None                 None  \n",
      "3                 None                 None  \n",
      "4                 None             positive  \n",
      "...                ...                  ...  \n",
      "4656              None                 None  \n",
      "4657          positive                 None  \n",
      "4658              None                 None  \n",
      "4659          negative             positive  \n",
      "4660              None             positive  \n",
      "\n",
      "[4661 rows x 4 columns]\n",
      "                                                review food_sentiment   \n",
      "0    Buff, No se donde empezar! El Servicio y la at...           None  \\\n",
      "1    Me gusto mucho el menú. Para no quedarse con h...           None   \n",
      "2    Gracias por tu crónica, me ha sido de gran ayu...           None   \n",
      "3    Muy bueno, calidad-precio. Pedimos menu de cal...       positive   \n",
      "4    Brugge is een mooie stad. De spareribs waren l...           None   \n",
      "..                                                 ...            ...   \n",
      "119  Gezellig tafelen in een bistro met aangename s...           None   \n",
      "120  Insultingly Overpriced - Mediocre Service/Qual...       negative   \n",
      "121  В субботу вечером пошли отмечать день рождение...       conflict   \n",
      "122  Excelente comida, pero escaso personal cuando ...       positive   \n",
      "123  Voor de 2de keer dit jaar gereserveerd in dit ...       positive   \n",
      "\n",
      "    service_sentiment atmosphere_sentiment  \n",
      "0            positive                 None  \n",
      "1                None                 None  \n",
      "2                None                 None  \n",
      "3            positive             positive  \n",
      "4            positive                 None  \n",
      "..                ...                  ...  \n",
      "119              None                 None  \n",
      "120          negative             positive  \n",
      "121          positive             negative  \n",
      "122              None                 None  \n",
      "123              None                 None  \n",
      "\n",
      "[124 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add 90 % of test data to train\n",
    "split = len(semval_test_df)//10\n",
    "semval_df = semval_df._append(semval_test_df[split:], ignore_index=True)\n",
    "semval_test_df = semval_test_df[:split]\n",
    "print(semval_df)\n",
    "print(semval_test_df)\n",
    "\n",
    "# prepare data for classification\n",
    "\n",
    "\n",
    "def map_val(x):\n",
    "    if x == 'positive':\n",
    "        return 1\n",
    "    elif x == 'negative':\n",
    "        return -1\n",
    "    elif x == 'neutral':\n",
    "        return 0\n",
    "    elif x == 'conflict':\n",
    "        return 0\n",
    "    elif x == None:\n",
    "        return None\n",
    "    else:\n",
    "        print(x)\n",
    "        raise Exception(\"an error occurred\")\n",
    "\n",
    "semval_df['food_sentiment'] = semval_df['food_sentiment'].apply(map_val)\n",
    "semval_df['service_sentiment'] = semval_df['service_sentiment'].apply(map_val)\n",
    "semval_df['atmosphere_sentiment'] = semval_df['atmosphere_sentiment'].apply(map_val)\n",
    "semval_test_df['food_sentiment'] = semval_test_df['food_sentiment'].apply(map_val)\n",
    "semval_test_df['service_sentiment'] = semval_test_df['service_sentiment'].apply(map_val)\n",
    "semval_test_df['atmosphere_sentiment'] = semval_test_df['atmosphere_sentiment'].apply(map_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7a27e0",
   "metadata": {},
   "source": [
    "### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3538ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_evaluation(array_true, array_pred):\n",
    "    mse = 0\n",
    "    num = 0\n",
    "    num_none = 0\n",
    "    correct_none = 0\n",
    "    for i in range(len(array_true)):\n",
    "        for j in range(len(array_true[i])):\n",
    "            true = array_true[i][j]\n",
    "            pred = array_pred[i][j]\n",
    "            if not np.isnan(true):\n",
    "                if not np.isnan(pred):\n",
    "                    mse += (true - pred)**2\n",
    "                    num += 1\n",
    "                else:\n",
    "                    num_none += 1\n",
    "            elif np.isnan(true):\n",
    "                if np.isnan(pred):\n",
    "                    correct_none += 1\n",
    "                num_none += 1\n",
    "    print(\"custom mse:\", mse/num)\n",
    "    print(\"none_accuracy:\", correct_none/num_none)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b05fe41",
   "metadata": {},
   "source": [
    "## Attempt 1: LLM API Zero-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a27ae0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter API key for Google Gemini: ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02d9bf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sehr leckeres Essen... Personal ist zudem sehr freundlich. [('food_sentiment', 0.9), ('service_sentiment', 0.9), ('atmoshphere_sentiment', None)]\n",
      "Ich war mit meiner Freundin in der meeega schõnen Besbeiz auf dem Bachtel. Einfach hammer. So nette freundliche Gastgeber. Das Plättli war reichhaltig und der Weisswein dazu mmmmmmh. Alles so liebevoll gemacht. Danke [('food_sentiment', 0.9), ('service_sentiment', 0.9), ('atmosphere_sentiment', 0.9)]\n",
      "Wir waren Mitte Januar im Restaurant,  also 2-3 Wochen nachdem der neue Pächter das Restaurant Bachtel übernahm...\n",
      "\n",
      "Aus der Lokalpresse haben wir vom Garderobe-Regim gelesen. Dass (grössere) Rucksäcke und Wanderstöcke abgegeben sollen fanden wir eine gute Idee. So bleibt Platz ungehindert zwischen den Tischen alle Gäste zu bedienen .\n",
      "\n",
      "Zum Lokal / Bedienung:\n",
      "Elegant,  es bleibt ansichtssache ob es für ein Bergrestaurant und normale Wanderer zu elegant ist. Schicki Micki wie hier schon geschrieben fanden wir es nicht. Zudem ist die Bedienung sehr freundlich\n",
      "\n",
      "Preis / Leistungsverhältnis:\n",
      "Der teller Käsespätzle qualitativ gut,  jedoch die Portion im vergleich zur Vorgängerpächterin kleiner und daher der Preis eher am oberen Rand!!\n",
      "Das gleiche gilt für die Getränke,  ein Capuccino für Fr. 6.00.. auch relativ oberes Preissegment. Was auffiel Getränkepreise standen nirgends auf der Karte. Ob gewollt oder dies ungewollt vergessen ging kann ich nicht beurteilen....\n",
      "Jetzt wo wir die Preise kennen,  trinken wir beim nächsten mal vielleicht nur 1  Getränk. . . .\n",
      "\n",
      "Die kleine Portion Vermicelle war super und von der Menge her gsehen preislich gut!\n",
      "\n",
      "Schnelligkeit der Bedienung:\n",
      "Das Restaurant war gut besucht,  nicht probenvoll (war auch bewölktes Wetter). Wirklich lange mussten wir nie warten,  ausser auf die Dessertkarte.. und da finde ich, die sollte auf Verlangen direkt gebracht werden (muss ja schliesslich nicht zuerst gekocht werden)\n",
      "\n",
      "Fazit:\n",
      "Es besteht noch Luft nach oben,  v.a. im Bezug auf Die Portionenmenge der Speisen und allgemein der Preise\n",
      "\n",
      "Da es unser Hausberg ist,  kommen wir sicher wieder und berichten auch über allfällige Veränderungen [('food_sentiment', 0.6), ('service_sentiment', 0.6), ('atmoshphere_sentiment', 0.8)]\n",
      "Preis - Leistung stimmte für nicht nicht! [('food_sentiment', None), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n",
      "Die Gerstensuppe war für meinen Geschmack ein bisschen dünn. Wir waren zu zweit und haben 3 Stück Brot erhalten? Naja, wir haben dann auf Anfrage Nachschub bekommen. Dafür waren der Apfelstrudel und das Vermicelles grosszügig bemessen.\n",
      "Konnten draussen auf der Terrasse essen, mit wunderbaren Blick über das Nebelmeer zu den Bergen. [('food_sentiment', 0.2), ('service_sentiment', 0.2), ('atmosphere_sentiment', 0.9)]\n",
      "Tolle Aussicht, Käse Spätzle waren super, etwas lange Wartezeiten aber super [('food_sentiment', 0.9), ('service_sentiment', -0.4), ('atmoshphere_sentiment', 0.8)]\n",
      "Sehr unfreundliches Personal!! Schade . [('food_sentiment', None), ('service_sentiment', -1.0), ('atmoshphere_sentiment', None)]\n",
      "Einfach super! Das Ambiente, die Bedienung, die Qualität, der Geschmack und Präsentation des Essens. Wir kommen definitiv wieder, sehr zu empfehlen! [('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmoshphere_sentiment', 1.0)]\n",
      "Best meal of our entire week vacation. Incredible chicken special and the spaetzle blew our minds. Do not leave zermatt without eating here. [('food_sentiment', 1.0), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n",
      "Beschte [('food_sentiment', None), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 17\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great location. Soooooo friendly people. Excellent food. 5star location. [('food_sentiment', 1.0), ('service_sentiment', 0.8), ('atmosphere_sentiment', 0.9)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 11\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 2\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oggi a pranzo.. carne e verdure sono arrivate fredde.. carne quasi cruda anche se chiesto cottura media.. nessuna scusa o ev.piccolo sconto per il disagio (piatto 44 fr) .. 2 camerieri molto indaffarati.. servizio un po’ sbrigativo anche se tutto sommato gentile.. non ci ritornerei più..peccato.. posizione ottima fronte lago [('food_sentiment', -0.9), ('service_sentiment', -0.4), ('atmoshphere_sentiment', 0.8)]\n",
      "Bijna 6 euro voor een colaatje is toch wel aan de prijzige kant. Locatie is wel super. [('food_sentiment', None), ('service_sentiment', None), ('atmosphere_sentiment', 1.0)]\n",
      "Wir (2 Personen) kamen um 20.30 Uhr ins Restaurant und wollten Pasta bestellen. Nicht nur, dass die Zutaten vo der Hälfte der Speisekarte schon ausgegangen waren, es gab auch keinen Parmesan und sonst keinen einzigen Reibkäse mehr. Klassische Touristenfalle mit einer überteuerten Speisekarte und nochmals: Welches italienische Restaurant hat um 20.30 keinerlei Käse mehr?!\n",
      "Absolut nicht zu empfehlen. [('food_sentiment', -0.9), ('service_sentiment', -0.7), ('atmoshphere_sentiment', None)]\n",
      "مطعم رائع بكل ماتعنيه الكلمه ولو فيع أكثر من 5نجوم يستاهلوها والله .. الأكل لذيذ جدا .. مقدمين الطلبات في قمة الأخلاق والذوق .. الجلسه مطله ع بحيرة لوجانو في منتهى الجمال [('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmoshphere_sentiment', 1.0)]\n",
      "Super moment passé. A découvrir avec plaisir! [('food_sentiment', None), ('service_sentiment', None), ('atmoshphere_sentiment', 0.9)]\n",
      "Bien et bonne ambiance\n",
      "Dommage du manque de sourire du patron [('food_sentiment', None), ('service_sentiment', -0.6), ('atmoshphere_sentiment', 0.8)]\n",
      "Sehr lecker, immer wieder gerne😋\n",
      "Una delicatesa [('food_sentiment', 0.9), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n",
      "Ich finde das Personal ausserordentlich freundlich! :)\n",
      "Das Essen schmeckt fantastisch und das Ambiente im Lokal lädt zum Verweilen ein.\n",
      "Gerne wieder! :D [('food_sentiment', 0.95), ('service_sentiment', 0.9), ('atmosphere_sentiment', 0.8)]\n",
      "Wir haben am letzten Freitag im 3692 das Jagtmenu genossen. Es war hervorragend, originell und eine Gaumenfreude . Unsere Freunde haben gesagt dass es das Beste war das sie je gegessen haben. Das Personal ist einfach top , die Besitzer haben uns königlich bewirtet , alle sind äusserst sympathisch und geerdet. Preis / Leistung ist spitze und das Ambiente muss man einfach einmal erleben.\n",
      "Vielen Dank und bis zum nächsten Mal [('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmoshphere_sentiment', 1.0)]\n",
      "그린델발트에 차를 가지고 왔다면 반드시 들러야할 곳. [('food_sentiment', None), ('service_sentiment', None), ('atmoshphere_sentiment', 0.9)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 19\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einmaliges Kaffee in Grindelwald. Sehr aufgestelltes Team. [('food_sentiment', 0.9), ('service_sentiment', 0.8), ('atmoshphere_sentiment', None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 12\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 4\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wir haben heute zum 1. Mal bestellt. Die Pizzen waren sehr lecker! Hier bestellen wir sehr gerne wieder. [('food_sentiment', 0.9), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n",
      "Das Essen ist sehr gut. Leider sind die Öffnungszeiten sehr unübersichtlich und nicht verlässlich [('food_sentiment', 0.8), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n",
      "super Bedienung trotz Regen Bravo [('food_sentiment', None), ('service_sentiment', 1.0), ('atmoshphere_sentiment', None)]\n",
      "We come here very often, its great stop during a wonderful hike in Klosters because the atmosphere and food are great. Its about 7km (hike along the river is easier as it has little elevations) you can make it easier and take bus till Mobiel and walk from there, it will be just about 2 km till the restaurant ( there are 2 main ways from Monbiel, the way that turns to the right and goes closer to the river is easier, good also for strollers)\n",
      "The restaurant has wonderful views and welcoming workers. The food is also very good. Lentil soup is nicely spicy (not too much) Älplermagronen with apple jam is also good. Hirschenwurst(dear sausage) is always great.\n",
      "Good thing for those who are done hiking is possibility to call for a taxi of horse carriage. The last is especially good in winter as it turns into horse sledges.\n",
      "Another important part for us is big playground for kids, so you can enjoy food and drinks while kids are busy on the trampoline. [('food_sentiment', 0.95), ('service_sentiment', 0.8), ('atmoshphere_sentiment', 0.9)]\n",
      "Sehr gutes Essen für Feste und Familienfeiern. [('food_sentiment', 0.9), ('service_sentiment', None), ('atmosphere_sentiment', None)]\n",
      "Sehr gutes Restaurant der gehobenen Klasse. Top Service, sehr freundlich. Fisch und Fleisch exzellent. Die Preise sind jedoch schon ziemlich hoch. [('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmoshphere_sentiment', 0.8)]\n",
      "Ich war das erste mal da, die Bedienung war freundlich und der Dürüm sehr lecker und gross. Preis Leistung stimmt. [('food_sentiment', 0.9), ('service_sentiment', 0.8), ('atmosphere_sentiment', None)]\n",
      "très bon restaurant [('food_sentiment', None), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n",
      "Super Winterurlaub [('food_sentiment', None), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n",
      "Gute Stimmung, gute Drinks, direkt nach der Talabfahrt zu erreichen [('food_sentiment', None), ('service_sentiment', None), ('atmosphere_sentiment', 0.9)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 19\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow [('food_sentiment', None), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 17\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 13\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certes la déco est assez basique mais la nourriture est très bonne, le service aimable et rapide, et une jolie vue sur le Léman depuis la terrasse.\n",
      "C'est aussi un point depot Breadstore pour du bon pain ou viennoiseries a emporter. [('food_sentiment', 0.8), ('service_sentiment', 0.7), ('atmoshphere_sentiment', 0.5)]\n",
      "Très chouette restaurant avec des plats recherchés et un service extrêmement souriant. J'ai adoré le cadre, la présentation et les mélanges de goûts très aboutis. Ce sera un plaisir de revenir tout bientôt. Encore un grand merci à tout le personnel ! [('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmoshphere_sentiment', 1.0)]\n",
      "Nettes Personal!\n",
      "Versteht manchmal meine Bestellungen nicht, weiss aber nicht genau wieso, sonst ist alles gut. [('food_sentiment', None), ('service_sentiment', 0.7), ('atmoshphere_sentiment', None)]\n",
      "Kleine Auswahl [('food_sentiment', None), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n",
      "Immer wieder! Das Essen, das Vini-Team, die Weine. Voll im Stress und trotzdem geduldig Fragen beantworten oder eine Weinempfehlung abgeben\n",
      "Immer wieder schön dort. 👍👍 [('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmoshphere_sentiment', 1.0)]\n",
      "Schöne grosse Terasse mitten unter Bäumen, schöne Steintische, echt tessinerisch, nettes Personal [('food_sentiment', None), ('service_sentiment', 0.8), ('atmoshphere_sentiment', 0.9)]\n",
      "Loved it! Right next to the bus stop, nice outdoor location, good mix of food options, nice atmosphere. [('food_sentiment', 0.7), ('service_sentiment', None), ('atmosphere_sentiment', 0.8)]\n",
      "Buono,personale gentile,nella bella val maggia [('food_sentiment', 0.7), ('service_sentiment', 0.8), ('atmoshphere_sentiment', 0.8)]\n",
      "Super [('food_sentiment', None), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n",
      "Die Pommes schmecken überhaupt nicht. Schmeckte komisch. Es war ohne Grund teuer. Denke nicht, dass ich dort wieder hingehen werde. [('food_sentiment', -0.9), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 10\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Super restaurant ! Service rapide, cuisine excellente et serveur très sympathique !\n",
      "Super cadre avec terasse au calme en plein centre de lucern !! [('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmoshphere_sentiment', 1.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 8\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 4\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very friendly and professional. There was a misunderstanding with my burger 🍔but they dealt with it professionally. Do not order a waygu beef burger and ask for the vegetarian version of it… there are probably better vegetarian alternatives 😅 my fault [('food_sentiment', -0.5), ('service_sentiment', 0.9), ('atmosphere_sentiment', None)]\n",
      "Waren nicht willkommen, wolten 3 Pers. etwas Essen und wurden abgewiessen sie seien zu wenig Personal sollen ins nächste Restaurant essen. [('food_sentiment', None), ('service_sentiment', -1.0), ('atmosphere_sentiment', -0.8)]\n",
      "Ich wollte eine Reservation machen er war sehr unfreundlich am Telefon und ich sollte ihm nicht während Mittagszeit anrufen es war 11.45 Uhr. Und er nahm sich die Frechheit und hängte das Telefon ab ohne um sagen ich soll später anrufen und sage auch nicht aufwiederhören aber nach mehreren Telefonaten nahm er endlich ab. Und so was Unfreundlichen brauche ich gar nicht es gibt ja auch andere Restaurant in Augst wo sehr freundlich sind und die Essens Qualität viel besser sind [('food_sentiment', -0.6), ('service_sentiment', -1.0), ('atmoshphere_sentiment', None)]\n",
      "Immer sehr gutes Essen und freundliche Bedienung [('food_sentiment', 0.9), ('service_sentiment', 0.8), ('atmoshphere_sentiment', None)]\n",
      "Sehr freundlichi Personal. Bestellung gleich aufgenommen und so Zeitnah serviert. Essen war sehr Qualitativ. Reumlichkeiten waren einwenig eng. [('food_sentiment', 0.9), ('service_sentiment', 0.9), ('atmoshphere_sentiment', -0.4)]\n",
      "Mi sono fermato in questo bar di fronte alla stazione pensando fosse una buona scelta per attendere chi doveva venirmi a prendere. Purtroppo è stata una delusione totale. L’accoglienza è stata pessima: nonostante il locale fosse mezzo vuoto, mi hanno fatto attendere senza motivo e con un atteggiamento decisamente scortese. Alla mia richiesta di una birra e della password del Wi-Fi, ho ricevuto risposte sbrigative e una poca empatia, come se stessi dando fastidio. Ciliegina sulla torta: mentre agli altri tavoli veniva servito un piccolo piattino con delle pizzette, a me non è stato portato nulla. Un trattamento davvero spiacevole, che mi ha fatto sentire ignorato e poco gradito. Non credo tornerò e non lo consiglio per fare una piccola pausa. Davvero pésimo !! [('food_sentiment', None), ('service_sentiment', -1.0), ('atmosphere_sentiment', None)]\n",
      "Great view, delicious food, and my man from Napoli, Alessandro was a gracious host. [('food_sentiment', 0.9), ('service_sentiment', 0.8), ('atmoshphere_sentiment', 0.8)]\n",
      "Tutto ottimo, un complimento ad Alessandro [('food_sentiment', None), ('service_sentiment', 1.0), ('atmoshphere_sentiment', None)]\n",
      "Abbiamo mangiato bene e Alessandro era ottimo! Grazie mille [('food_sentiment', 0.7), ('service_sentiment', 0.9), ('atmoshphere_sentiment', None)]\n",
      "Great atmosphere, delicious risotto, and amazing view! Big thanks to our amazing staff who made it more special - thanks to Giovanni and Alfonso! Would definitely go again and recommend it. [('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmoshphere_sentiment', 1.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 27\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very scrumptuous Solo Lunch, I had the pleasure of being waited by Marcello. The service was impeccable, including the suggestions ! Very good waiter who made what seemed like a tourist trap at first result in an amazing lunch. I definitely Recommend having lunch there if you must stay near the train station. [('food_sentiment', 0.9), ('service_sentiment', 1.0), ('atmosphere_sentiment', None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 25\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 20\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 12\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peccato perché tempo fa avevo dato un bel punteggio a questo posto che ha un bel panorama,e anche l'ambiente è bello,ma ultimamente non so che sia successo!staff poco motivato a lavorare, tempi esagerati per prendere un'ordinazione,i prezzi sono alti e non ne vale più la pena perché manca la serietà e professionalità del personale, e la qualità del cibo e servizio.P.s consiglio di controllare di più chi lavora la selezione di personale seriamente motivato e che ci mette passione in ciò che fa' e il successo per andare avanti bene e qui manca totalmente. [('food_sentiment', -0.8), ('service_sentiment', -1.0), ('atmoshphere_sentiment', 0.8)]\n",
      "Se avessi potuto mettere 0 stelle, le avrei messe volentieri.\n",
      "La location è ottima ed il panorama eccellente, ma i pregi finiscono qui.\n",
      "Il servizio è scortese ed acido, abbiamo ordinato 4 caffè che sono arrivati dopo 25min di attesa, inoltre è inammissibile che un bar che prepari colazioni, non tratti croissant e brioche, dopo ulteriori 10min di attesa, nonostante il locale fosse vuoto e le numerose richieste di avere le consumazioni, ci hanno servito una torta della nonna completamente ghiacciata, immangiabile, e per finire, la beffa: 4 caffè ed una torta della nonna, 35fr. [('food_sentiment', -1.0), ('service_sentiment', -1.0), ('atmoshphere_sentiment', 0.9)]\n",
      "Ristorante piacevole e con una vista straordinaria sulla città di Lugano.\n",
      "Il cibo è gustoso e come prezzi abbastanza in linea con i prezzi della città.\n",
      "Vale una visita, sopratutto se in attesa di coincidenza di treni per Zurigo. [('food_sentiment', 0.7), ('service_sentiment', None), ('atmoshphere_sentiment', 0.9)]\n",
      "Restaurant italien traditionnel se trouvant sur les hauts de Lugano et proposant pizza, risotto, pâte, antipasti et poisson. Les prix sont dans la moyenne pour ce type de restaurant à Lugano et les employés sont symphatiques. L'intéret de cet établissement est la terrasse donnant un point de vue sur Lugano, le Monte Brè et une partie du lac de Lugano.\n",
      "Parking de la gare CFF de Lugano à proximité. [('food_sentiment', None), ('service_sentiment', 0.8), ('atmoshphere_sentiment', 0.95)]\n",
      "Très joli restaurant de campagne,  très bonne accueil, service impeccable, très bien mangé un établissement tenu par des professionnels. A recommander [('food_sentiment', 0.9), ('service_sentiment', 1.0), ('atmosphere_sentiment', 0.9)]\n",
      "Bien [('food_sentiment', None), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n",
      "schon lange sind wir nicht mehr so nett begrüsst und bewirtet worden. Essen war spitze und die drinks auch [('food_sentiment', 0.9), ('service_sentiment', 0.9), ('atmoshphere_sentiment', None)]\n",
      "Sono stata per un compleanno. Tempi di attesa improponibili, tenendo anche in conto che c'erano bambini abbiamo atteso 2h per la portata principale nonostante fosse praticamente vuoto, nonostante lattesa i piatti sono arrivati con 15min di differenza uno dell'altro. Il servizio è stato pessimo a dir poco. Ho chiesto un piatto presente sul menù e con una maleducazione inaudita mi è stato detto \"NO, quello no... lo abbiamo finito!\" Come se io dovevo saperlo.\n",
      "La pasta era immagiabile, annegata nel Olio. I dolci erano di una tirchianaggine assurda.\n",
      "I prezzi alti qualità e servizio avuto a quel pranzo non lo giustificano minimamente.\n",
      "Sconsiglio e sicuramente non ci tornerò [('food_sentiment', -1.0), ('service_sentiment', -1.0), ('atmosphere_sentiment', None)]\n",
      "Conosco personalmente lo chef vi assicuro che si impegna sempre al massimo per soddisfare qualsiasi esigenza. Persona affidabilissima. Prepara i suoi piatti con grande passione.\n",
      "Giambattista Taboni. Monte Carasso [('food_sentiment', 0.9), ('service_sentiment', 0.8), ('atmoshphere_sentiment', None)]\n",
      "Angy best service👍 [('food_sentiment', None), ('service_sentiment', 1.0), ('atmoshphere_sentiment', None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spannende Mischung aus Restaurant und Musikbar. Ein schöner Abend mit wirklich ganz ausgezeichnetem Essen (und für Züricher Verhältnisse super Preis-Leistungsverhältnis). [('food_sentiment', 0.95), ('service_sentiment', None), ('atmoshphere_sentiment', 0.7)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 22\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 18\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 10\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schon lange nicht mehr so gut gegessen. Die Menus waren super lecker, das Personal sehr freundlich und die Einrichtung toll.\n",
      "Wir werden sicherlich wiederkommen! [('food_sentiment', 1.0), ('service_sentiment', 0.9), ('atmoshphere_sentiment', 0.8)]\n",
      "Mauvaise expérience. .salle à manger laisse à désirer nappes sets pas repasseés  cuisine juste acceptable  1ere et dernière fois!! [('food_sentiment', -0.3), ('service_sentiment', None), ('atmoshphere_sentiment', -0.8)]\n",
      "Burgers too expensive [('food_sentiment', -0.6), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n",
      "Need to improve service level [('food_sentiment', None), ('service_sentiment', -0.8), ('atmosphere_sentiment', None)]\n",
      "Immer wieder ein Erlebnis. Super Essen, nette Bedienung. [('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmoshphere_sentiment', None)]\n",
      "Sehr tolles Restaurant mit viel Charme. Sehr gutes essen. [('food_sentiment', 0.9), ('service_sentiment', None), ('atmoshphere_sentiment', 0.9)]\n",
      "Tolles Essen. Tolles Ambiente! Nette Bedienung! [('food_sentiment', 1.0), ('service_sentiment', 0.8), ('atmoshphere_sentiment', 1.0)]\n",
      "Cooles Restaurant mit einer grossen Essens- und Getränkeauswahl. Hier findet man vieles, das man sonst nirgends findet. Die Deko ist auch interessant und es gibt jede Menge zu entdecken. Leider ist es am Wochenende pure Massenabfertigung und eine Reservierung zu tätigen ist gar nicht so einfach. [('food_sentiment', 0.8), ('service_sentiment', -0.7), ('atmoshphere_sentiment', 0.7)]\n",
      "Dort gibt es so ziemlich alle Bier 🍺 Sorten die man sich vorstellen kann. Wer auf American Food steht ist dort gut aufgehoben. (Essen super). Tisch Reservierung ist zu empfehlen. [('food_sentiment', 1.0), ('service_sentiment', None), ('atmoshphere_sentiment', 0.6)]\n",
      "Great food, valuable prices! We'll visit you again 😎🤟 [('food_sentiment', 1.0), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 30\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wie emmer ...absolute Burger Hammer.dezue no fröndlichs Personal cooli atmosphäre..eifach e geile schoppe [('food_sentiment', 1.0), ('service_sentiment', 0.9), ('atmosphere_sentiment', 0.8)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cooles Restaurant, fein gegessen, gibt viel zu entdecken. [('food_sentiment', 0.9), ('service_sentiment', None), ('atmoshphere_sentiment', 0.9)]\n",
      "Es hat sich nichts geändert. Immer noch das gleich gute Essen wie früher zu einem absolut vernünftigen Preis. Für die Bedienung gilt das selbe. War rund um zufrieden 😃 Für mich immer wieder einen Ausflug wert. [('food_sentiment', 0.9), ('service_sentiment', 0.9), ('atmoshphere_sentiment', None)]\n",
      "Immer wieder gern. Top Qualität und nette Bedienung [('food_sentiment', 0.8), ('service_sentiment', 0.9), ('atmoshphere_sentiment', None)]\n",
      "Geht so,überfüllt [('food_sentiment', None), ('service_sentiment', None), ('atmoshphere_sentiment', -0.7)]\n",
      "Richtig klasse Burger! Sehr tolles Restaurant mit toller amerikanischer Atmosphäre [('food_sentiment', 1.0), ('service_sentiment', None), ('atmoshphere_sentiment', 1.0)]\n",
      "Bereits an der Türe wurden wir herzlich Willkommen geheissen. In einer schönen Ambiente durften wir einen genussvollen Abend verbringen. Angefangen mit dem Hausaperò, der die Geschmacksnerven zum Leben erweckte. Der Hauptgang, raffiniert angerichtet, mit dem passenden Rotwein dazu, vollmundig und  exquisit. Das hausgemachte Dessert war das Tüpfelchen auf dem i.\n",
      "Ich, von meiner Seite, werde wiederkommen und kann dieses Restaurant nur weiterempfehlen. Sowohl Küche wie auch Service TOP [('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmoshphere_sentiment', 0.9)]\n",
      "Was a bit diappointed about the long waiting time (close to 50 minutes) for a Hamburger with french fries, taking into account that they operate with a reduced menu card durind lunch time. But at the end the Hamburger was tasty. [('food_sentiment', 0.7), ('service_sentiment', -0.8), ('atmoshphere_sentiment', None)]\n",
      "Trotz hochbetrieb und Anlass, freundlich und sehr schnelle Essens-Lieferung! Wir kommen wieder 🖤🤍🤘🏽 [('food_sentiment', None), ('service_sentiment', 1.0), ('atmoshphere_sentiment', None)]\n",
      "Samstag und Sonntag sind immer treffen zu bestimmten Themen die mit töf und auto zu tun haben sowie auch flohmarkt tolles Kaffee super Atmosphäre lohnt sich vorbei zu schauen wie gewohnt gut 👍 [('food_sentiment', 0.9), ('service_sentiment', None), ('atmosphere_sentiment', 0.95)]\n",
      "Während man als Deutscher überhaupt auf die Bestellaufnahme wartet obwohl schon 3 mal auf sich aufmerksam gemacht bekommen die alten Schweizer Damen am Nachbartisch, die nach uns kamen, den vollen Service...\n",
      "Und es kann keiner sagen dass die überfordert sind... Es war nicht einmal halb voll draussen... drinnen war es völlig leer...\n",
      "Alles nur hipster und hochnäsige Individuen! [('food_sentiment', None), ('service_sentiment', -1.0), ('atmosphere_sentiment', -0.8)]\n",
      "Einfach extrem lecker und ein super Ambiente. Die Event sind auch immer Top. [('food_sentiment', 1.0), ('service_sentiment', None), ('atmoshphere_sentiment', 1.0)]\n",
      "War mega super tolles Essen freundlich die Bedienung ich werde wieder hin gehen 🤟🖐🖐🖐 [('food_sentiment', 1.0), ('service_sentiment', 0.8), ('atmoshphere_sentiment', None)]\n",
      "Hallo,\n",
      "Wisst ihr was ich bei euch vermisse und zwar fest in der Karte: Den Pulled Lachs Burger👌.....\n",
      "Vor Corona hattet ihr den Lachs-Burger mal drauf und der war HAMMER🙏🙏🙏......bitte nehmt in in der Karte auf🙏.\n",
      "Ansonsten gibts nichts zu Mekern bei euch. Service von Nino ist TOP und immer Lustig🥰 Danke. Der Weisswein K-Naia ist echt Super.\n",
      "Lg Ruth & Oli [('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmosphere_sentiment', None)]\n",
      "Immer wieder eine fabelhafte und gemütliche Stimmung\n",
      "Gutes Bier, gutes Essen, was will man mehr [('food_sentiment', 0.8), ('service_sentiment', None), ('atmoshphere_sentiment', 0.9)]\n",
      "Sehr schnelles Service, sehr sympatisches und speditives Personal auch bei hektischen Situationen, Preis für meine Empfindung ein bisschen hoch sonst super nur so weiter,👌 [('food_sentiment', None), ('service_sentiment', 1.0), ('atmosphere_sentiment', None)]\n",
      "Das Mekka aller Motorradfahrer, in der Schweiz, gepaart mit super leckeren Essen und Trinken mit jeder Menge Spass. Auch für die kleinsten ist gesorgt und die älteren lieben die Mischung aus Motorsound Essen und hübschen Frauen ♀ [('food_sentiment', 0.9), ('service_sentiment', None), ('atmoshphere_sentiment', 1.0)]\n",
      "Super Stimmung und gutes Essen, passt alles [('food_sentiment', 0.8), ('service_sentiment', None), ('atmoshphere_sentiment', 0.9)]\n",
      "Einfach nur Wow!!\n",
      "\n",
      "Geniales Essen, super freundliches Personal und gute Events 👍🏻 [('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmoshphere_sentiment', 0.75)]\n",
      "Obercool immer [('food_sentiment', None), ('service_sentiment', None), ('atmoshphere_sentiment', 1.0)]\n",
      "Die besten Burger bekomt mann im ACE Cafe 🤘🤙👌 [('food_sentiment', 1.0), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n",
      "Not quite the original, but let's see [('food_sentiment', None), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 30\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hoi Dani und Team.\n",
      "Will auch mal meinen Senf dazugeben.\n",
      "Top Top Top. Mehr kann ich nicht sagen. Mein zweites zu Hause. Greez Börni [('food_sentiment', None), ('service_sentiment', 0.9), ('atmoshphere_sentiment', 1.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 24\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 16\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Des plats délicieux et un accueil chaleureux et très agréable [('food_sentiment', 0.9), ('service_sentiment', 0.9), ('atmosphere_sentiment', None)]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "text = \"Please perform Aspect-Based Sentiment Classification task on google maps reviews. \\\n",
    "Given a review, classify each (sentiment, rating) pair. \\\n",
    "Sentiments are ['food_sentiment', 'service_sentiment', 'atmoshphere_sentiment']. \\\n",
    "'food_sentiment' should answer: What does the review say about how good the food was? \\\n",
    "'service_sentiment' should answer: What does the review say about how good the service was? \\\n",
    "'atmosphere_sentiment' should answer: What does the review say about how good the atmoshpere was? \\\n",
    "Ratings should be selected as a floating point number from -1 to 1. Where 1 means excellent, above all expectations, and -1 means the worst ever experienced. \\\n",
    "If a sentiment does not apply, its rating should be the python Value 'None'. \\\n",
    "This also applies to short reviews like 'Great!'.\\\n",
    "Always return a valid python list of tuples containing a string in single quotes and a float for each sentiment.\\\n",
    "Please return python list only, without any other comments or texts.\"\n",
    "\n",
    "\n",
    "output = []\n",
    "for sentence in gold_df.review.to_list():\n",
    "    messages = [\n",
    "        SystemMessage(content=text),\n",
    "        HumanMessage(content=sentence),\n",
    "    ]\n",
    "    output.append(model.invoke(messages).content)\n",
    "    print(sentence, output[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c54d1014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9   0.9    nan]\n",
      " [ 0.9   0.9   0.9 ]\n",
      " [ 0.6   0.6   0.8 ]\n",
      " [  nan   nan   nan]\n",
      " [ 0.2   0.2   0.9 ]\n",
      " [ 0.9  -0.4   0.8 ]\n",
      " [  nan -1.     nan]\n",
      " [ 1.    1.    1.  ]\n",
      " [ 1.     nan   nan]\n",
      " [  nan   nan   nan]\n",
      " [ 1.    0.8   0.9 ]\n",
      " [-0.9  -0.4   0.8 ]\n",
      " [  nan   nan  1.  ]\n",
      " [-0.9  -0.7    nan]\n",
      " [ 1.    1.    1.  ]\n",
      " [  nan   nan  0.9 ]\n",
      " [  nan -0.6   0.8 ]\n",
      " [ 0.9    nan   nan]\n",
      " [ 0.95  0.9   0.8 ]\n",
      " [ 1.    1.    1.  ]\n",
      " [  nan   nan  0.9 ]\n",
      " [ 0.9   0.8    nan]\n",
      " [ 0.9    nan   nan]\n",
      " [ 0.8    nan   nan]\n",
      " [  nan  1.     nan]\n",
      " [ 0.95  0.8   0.9 ]\n",
      " [ 0.9    nan   nan]\n",
      " [ 1.    1.    0.8 ]\n",
      " [ 0.9   0.8    nan]\n",
      " [  nan   nan   nan]\n",
      " [  nan   nan   nan]\n",
      " [  nan   nan  0.9 ]\n",
      " [  nan   nan   nan]\n",
      " [ 0.8   0.7   0.5 ]\n",
      " [ 1.    1.    1.  ]\n",
      " [  nan  0.7    nan]\n",
      " [  nan   nan   nan]\n",
      " [ 1.    1.    1.  ]\n",
      " [  nan  0.8   0.9 ]\n",
      " [ 0.7    nan  0.8 ]\n",
      " [ 0.7   0.8   0.8 ]\n",
      " [  nan   nan   nan]\n",
      " [-0.9    nan   nan]\n",
      " [ 1.    1.    1.  ]\n",
      " [-0.5   0.9    nan]\n",
      " [  nan -1.   -0.8 ]\n",
      " [-0.6  -1.     nan]\n",
      " [ 0.9   0.8    nan]\n",
      " [ 0.9   0.9  -0.4 ]\n",
      " [  nan -1.     nan]\n",
      " [ 0.9   0.8   0.8 ]\n",
      " [  nan  1.     nan]\n",
      " [ 0.7   0.9    nan]\n",
      " [ 1.    1.    1.  ]\n",
      " [ 0.9   1.     nan]\n",
      " [-0.8  -1.    0.8 ]\n",
      " [-1.   -1.    0.9 ]\n",
      " [ 0.7    nan  0.9 ]\n",
      " [  nan  0.8   0.95]\n",
      " [ 0.9   1.    0.9 ]\n",
      " [  nan   nan   nan]\n",
      " [ 0.9   0.9    nan]\n",
      " [-1.   -1.     nan]\n",
      " [ 0.9   0.8    nan]\n",
      " [  nan  1.     nan]\n",
      " [ 0.95   nan  0.7 ]\n",
      " [ 1.    0.9   0.8 ]\n",
      " [-0.3    nan -0.8 ]\n",
      " [-0.6    nan   nan]\n",
      " [  nan -0.8    nan]\n",
      " [ 1.    1.     nan]\n",
      " [ 0.9    nan  0.9 ]\n",
      " [ 1.    0.8   1.  ]\n",
      " [ 0.8  -0.7   0.7 ]\n",
      " [ 1.     nan  0.6 ]\n",
      " [ 1.     nan   nan]\n",
      " [ 1.    0.9   0.8 ]\n",
      " [ 0.9    nan  0.9 ]\n",
      " [ 0.9   0.9    nan]\n",
      " [ 0.8   0.9    nan]\n",
      " [  nan   nan -0.7 ]\n",
      " [ 1.     nan  1.  ]\n",
      " [ 1.    1.    0.9 ]\n",
      " [ 0.7  -0.8    nan]\n",
      " [  nan  1.     nan]\n",
      " [ 0.9    nan  0.95]\n",
      " [  nan -1.   -0.8 ]\n",
      " [ 1.     nan  1.  ]\n",
      " [ 1.    0.8    nan]\n",
      " [ 1.    1.     nan]\n",
      " [ 0.8    nan  0.9 ]\n",
      " [  nan  1.     nan]\n",
      " [ 0.9    nan  1.  ]\n",
      " [ 0.8    nan  0.9 ]\n",
      " [ 1.    1.    0.75]\n",
      " [  nan   nan  1.  ]\n",
      " [ 1.     nan   nan]\n",
      " [  nan   nan   nan]\n",
      " [  nan  0.9   1.  ]\n",
      " [ 0.9   0.9    nan]] [[ 0.9  0.6  nan]\n",
      " [ 0.5  0.8  0.6]\n",
      " [ 0.4  0.6  0.3]\n",
      " [ nan  nan  nan]\n",
      " [-0.2  nan  0.8]\n",
      " [ 0.6 -0.1  0.5]\n",
      " [ nan -0.8  nan]\n",
      " [ 0.8  0.7  0.7]\n",
      " [ 1.   nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ 0.7  0.8  nan]\n",
      " [-0.9 -0.3  0.3]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ 0.9  0.8  0.8]\n",
      " [ nan  nan  nan]\n",
      " [ nan -0.4  0.6]\n",
      " [ 0.9  nan  nan]\n",
      " [ 0.8  0.8  0.7]\n",
      " [ 1.   1.   0.7]\n",
      " [ nan  nan  nan]\n",
      " [ nan  0.5  nan]\n",
      " [ 0.8  nan  nan]\n",
      " [ 0.7  nan  nan]\n",
      " [ nan  0.7  nan]\n",
      " [ 0.8  0.7  0.8]\n",
      " [ 0.5  nan  nan]\n",
      " [ 0.5  0.7  nan]\n",
      " [ 0.8  0.5  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ 0.3  nan  0.4]\n",
      " [ nan  nan  nan]\n",
      " [ 0.7  0.6  0.1]\n",
      " [ 0.8  0.9  0.5]\n",
      " [ nan  0.3  nan]\n",
      " [ nan  nan  nan]\n",
      " [ 0.6  0.6  nan]\n",
      " [ nan  0.4  0.6]\n",
      " [ 0.2  nan  0.6]\n",
      " [ nan  0.5  nan]\n",
      " [ nan  nan  nan]\n",
      " [-0.5  nan  nan]\n",
      " [ 0.9  0.9  0.8]\n",
      " [-0.1  0.6  nan]\n",
      " [ nan -0.7  nan]\n",
      " [-0.4 -0.8  nan]\n",
      " [ 0.7  0.5  nan]\n",
      " [ 0.6  0.8 -0.2]\n",
      " [ nan -0.8  nan]\n",
      " [ 0.8  0.8  0.6]\n",
      " [ nan  nan  nan]\n",
      " [ 0.6  0.6  nan]\n",
      " [ 0.7  0.8  0.7]\n",
      " [ nan  0.9  nan]\n",
      " [-0.3 -0.7  0.9]\n",
      " [-0.5 -0.8  0.3]\n",
      " [ 0.5  nan  0.3]\n",
      " [ nan  0.4  0.7]\n",
      " [ 0.7  0.8  nan]\n",
      " [ nan  nan  nan]\n",
      " [ 0.7  0.9  nan]\n",
      " [-0.9 -0.9  nan]\n",
      " [ nan  0.6  nan]\n",
      " [ nan  0.7  nan]\n",
      " [ 0.8  nan  0.3]\n",
      " [ 0.9  0.6  0.4]\n",
      " [-0.2  nan -0.7]\n",
      " [ nan  nan  nan]\n",
      " [ nan -0.3  nan]\n",
      " [ 0.7  0.5  nan]\n",
      " [ 0.7  nan  0.5]\n",
      " [ 0.5  0.5  0.5]\n",
      " [ nan -0.1  0.4]\n",
      " [ 0.7  nan  nan]\n",
      " [ 0.7  nan  nan]\n",
      " [ 0.8  0.7  0.7]\n",
      " [ 0.6  nan  0.5]\n",
      " [ 0.5  0.5  nan]\n",
      " [ nan  0.5  nan]\n",
      " [ nan  nan -0.3]\n",
      " [ 0.7  nan  0.6]\n",
      " [ 1.   0.7  0.7]\n",
      " [ 0.6  nan  nan]\n",
      " [ nan  0.6  nan]\n",
      " [ nan  nan  0.7]\n",
      " [ nan -0.8  nan]\n",
      " [ 0.7  nan  0.6]\n",
      " [ 0.8  0.5  nan]\n",
      " [ 0.6  0.8  nan]\n",
      " [ 0.5  nan  0.7]\n",
      " [ nan  0.6  nan]\n",
      " [ 0.7  nan  0.6]\n",
      " [ 0.5  nan  0.5]\n",
      " [ 0.7  0.8  nan]\n",
      " [ nan  nan  nan]\n",
      " [ 0.6  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ nan  nan  nan]\n",
      " [ 0.6  0.7  nan]]\n",
      "<class 'numpy.float64'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11238333333333332"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_list = []\n",
    "for el in output:\n",
    "    new_list.append([eval(el)[0][1], eval(el)[1][1], eval(el)[2][1]])\n",
    "array_list = np.array(new_list, dtype=float)\n",
    "array_gold = gold_df[['food_sentiment', 'service_sentiment','atmosphere_sentiment']].to_numpy()\n",
    "print(array_list, array_gold)\n",
    "\n",
    "# TODO: \n",
    "# - Also get the semeval test data\n",
    "# - Manually compute MSE on non-None datapoints\n",
    "# - seperate evaluation for None-prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "78fae4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom mse: 0.08643081761006281\n",
      "none_accuracy: 0.7943262411347518\n"
     ]
    }
   ],
   "source": [
    "new_list = []\n",
    "for el in output:\n",
    "    new_list.append([eval(el)[0][1], eval(el)[1][1], eval(el)[2][1]])\n",
    "array_list = np.array(new_list, dtype=float)\n",
    "array_gold = gold_df[['food_sentiment', 'service_sentiment','atmosphere_sentiment']].to_numpy()\n",
    "custom_evaluation(array_gold, array_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b08393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ad6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 1 example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928fafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output shape and output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94166d75",
   "metadata": {},
   "source": [
    "## Version 2: Sentence Transformer + Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9141234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05374188  0.02473747 -0.0658299  ... -0.04611053 -0.02515517\n",
      "   0.04287363]\n",
      " [-0.04497419  0.00086342 -0.06089868 ...  0.04534195 -0.0147701\n",
      "  -0.00831271]\n",
      " [-0.06915811  0.02920406 -0.05219717 ... -0.06375841 -0.03812444\n",
      "  -0.05758743]\n",
      " ...\n",
      " [-0.02360004  0.00674012 -0.06065604 ... -0.02075107 -0.00098548\n",
      "  -0.02820507]\n",
      " [-0.06009253  0.00052821 -0.04462495 ...  0.00054765 -0.02710088\n",
      "   0.00686717]\n",
      " [-0.05119808  0.04513644 -0.06845779 ... -0.02770323  0.01709087\n",
      "  -0.00049522]]\n",
      "(4661, 768)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/LaBSE', token='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')\n",
    "embeddings = model.encode(semval_df.review.to_list())\n",
    "print(embeddings)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86a344c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "y_food = semval_df.food_sentiment.to_list()\n",
    "y_service = semval_df.service_sentiment.to_list()\n",
    "y_atmosphere = semval_df.atmosphere_sentiment.to_list()\n",
    "y_none = zip(y_food, y_service, y_atmosphere)\n",
    "\n",
    "def map_values(x):\n",
    "    if x == None or np.isnan(x):\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "y_food = list(map(map_values, y_food))\n",
    "y_service = list(map(map_values, y_service))\n",
    "y_atmosphere = list(map(map_values, y_atmosphere))\n",
    "\n",
    "def map_none(x):\n",
    "    if x == None or np.isnan(x):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "y_none = [list(map(map_none, el)) for el in y_none]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf7236d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    embeddings, list(zip(y_food, y_service, y_atmosphere, y_none)), test_size=0.33, random_state=42)\n",
    "y_train_food, y_train_service, y_train_atmosphere, y_train_none = zip(*y_train)\n",
    "y_test_food, y_test_service, y_test_atmosphere, y_test_none = zip(*y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2028e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_food = MLPRegressor(random_state=1, hidden_layer_sizes=(100,100), max_iter=2000, tol=0.1).fit(X_train, y_train_food)\n",
    "reg_service = MLPRegressor(random_state=1, max_iter=2000,  hidden_layer_sizes=(100,100), tol=0.1).fit(X_train, y_train_service)\n",
    "reg_atmosphere = MLPRegressor(random_state=1, max_iter=2000,  hidden_layer_sizes=(100,100), tol=0.1).fit(X_train, y_train_atmosphere)\n",
    "clf_none = MLPClassifier(random_state=1, hidden_layer_sizes=(100,100), max_iter=300).fit(X_train, y_train_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2c1f4335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom mse: 0.11714554220811242\n",
      "none_accuracy: 0.5714285714285714\n",
      "custom mse: 0.26012193527332644\n",
      "none_accuracy: 0.4409937888198758\n"
     ]
    }
   ],
   "source": [
    "array_gold = gold_df_dev[['food_sentiment', 'service_sentiment','atmosphere_sentiment']].to_numpy()\n",
    "array_semval = semval_test_df[['food_sentiment', 'service_sentiment','atmosphere_sentiment']].to_numpy()\n",
    "embeddings_gold = model.encode(gold_df_dev.review.to_list())\n",
    "embeddings_semval = model.encode(semval_test_df.review.to_list())\n",
    "\n",
    "array_pred_gold = np.array(list(zip(reg_food.predict(embeddings_gold), \n",
    "                      reg_service.predict(embeddings_gold), \n",
    "                      reg_atmosphere.predict(embeddings_gold))))\n",
    "none_array_gold = np.array(clf_none.predict(embeddings_gold))\n",
    "array_pred_gold[none_array_gold == 1] = None\n",
    "\n",
    "array_pred_semval = np.array(list(zip(reg_food.predict(embeddings_semval), \n",
    "                      reg_service.predict(embeddings_semval), \n",
    "                      reg_atmosphere.predict(embeddings_semval))))\n",
    "none_array_semval = np.array(clf_none.predict(embeddings_semval))\n",
    "array_pred_semval[none_array_semval == 1] = None\n",
    "\n",
    "custom_evaluation(array_gold, array_pred_gold)\n",
    "custom_evaluation(array_semval, array_pred_semval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73904a9",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c32c5a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000], Loss: 0.3694\n",
      "Epoch [2/10000], Loss: 0.3649\n",
      "Epoch [3/10000], Loss: 0.3652\n",
      "Epoch [4/10000], Loss: 0.3656\n",
      "Epoch [5/10000], Loss: 0.3648\n",
      "Epoch [6/10000], Loss: 0.3641\n",
      "Epoch [7/10000], Loss: 0.3644\n",
      "Epoch [8/10000], Loss: 0.3645\n",
      "Epoch [9/10000], Loss: 0.3645\n",
      "Epoch [10/10000], Loss: 0.3647\n",
      "Epoch [11/10000], Loss: 0.3647\n",
      "Epoch [12/10000], Loss: 0.3644\n",
      "Epoch [13/10000], Loss: 0.3642\n",
      "Epoch [14/10000], Loss: 0.3663\n",
      "Epoch [15/10000], Loss: 0.3637\n",
      "Epoch [16/10000], Loss: 0.3643\n",
      "Epoch [17/10000], Loss: 0.3650\n",
      "Epoch [18/10000], Loss: 0.3643\n",
      "Epoch [19/10000], Loss: 0.3637\n",
      "Epoch [20/10000], Loss: 0.3640\n",
      "Epoch [21/10000], Loss: 0.3644\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m model \u001b[38;5;241m=\u001b[39m RegressionModel()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Example inference\u001b[39;00m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[0;32mIn[63], line 39\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, X_train, y_train, num_epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     36\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_X, batch_y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m#print(outputs, batch_y)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m#print(outputs)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[63], line 16\u001b[0m, in \u001b[0;36mRegressionModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x))\n\u001b[0;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the regression model\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_size=768):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 256*8)\n",
    "        self.layer2 = nn.Linear(256*8, 64)\n",
    "        self.layer3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# Training function\n",
    "def train_model(model, X_train, y_train, num_epochs=10000, batch_size=32, learning_rate=0.001):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Convert data to tensors\n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "    y_train = torch.FloatTensor(y_train)\n",
    "    \n",
    "    # Create data loader\n",
    "    dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            # Forward pass\n",
    "            outputs = model(batch_X)\n",
    "            #print(outputs, batch_y)\n",
    "\n",
    "            #print(outputs)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        if (epoch + 1) % 1== 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate sample data\n",
    "    n_samples = len(y_train_food)\n",
    "    X_train = X_train  # 1000 samples with 768 features\n",
    "    y_train = y_train_food  # 1000 target values\n",
    "    # Initialize model\n",
    "    model = RegressionModel()\n",
    "    \n",
    "    # Train the model\n",
    "    train_model(model, X_train, y_train)\n",
    "    \n",
    "    # Example inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sample_input = torch.FloatTensor(X_test[1])\n",
    "        prediction = model(sample_input)\n",
    "        print(f\"Sample prediction: {prediction.item():.4f}\")\n",
    "    print(y_test_food[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b80499",
   "metadata": {},
   "source": [
    "## Version 3: NLP Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11990640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a806a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a93406b1",
   "metadata": {},
   "source": [
    "## Version 4: DeepInfra LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d52fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# or pass deepinfra_api_token parameter to the ChatDeepInfra constructor\n",
    "os.environ[\"DEEPINFRA_API_TOKEN\"] = 'HXms0jvIhtZd9aEEjSaLGlo65QY8zKbL'\n",
    "\n",
    "from langchain_community.chat_models import ChatDeepInfra\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "\n",
    "text = \"Please perform Aspect-Based Sentiment Classification task on google maps reviews. \\\n",
    "Given a review, classify each (sentiment, rating) pair. \\\n",
    "Sentiments are ['food_sentiment', 'service_sentiment', 'atmosphere_sentiment']. \\\n",
    "'food_sentiment' should answer: What does the review say about how good the food was? \\\n",
    "'service_sentiment' should answer: What does the review say about how good the service was? \\\n",
    "'atmosphere_sentiment' should answer: What does the review say about how good the atmoshpere was? \\\n",
    "Ratings should be selected as a floating point number from -1 to 1. Where 1 means excellent, above all expectations, and -1 means the worst ever experienced. \\\n",
    "If a sentiment does not apply, its rating should be the python Value 'None'. \\\n",
    "This also applies to short reviews like 'Great!'.\\\n",
    "Always return a valid python list of tuples containing a string in single quotes and a float for each sentiment.\\\n",
    "Please return a python list only, without any other comments or texts.\\\n",
    "Always keep the order of the sentiments the same!\"\n",
    "\n",
    "\n",
    "output = []\n",
    "sentences = gold_df_dev.review.to_list()\n",
    "messages = []\n",
    "for sentence in sentences:\n",
    "    messages.append([\n",
    "        SystemMessage(content=text),\n",
    "        HumanMessage(content=sentence)\n",
    "    ])\n",
    "    \n",
    "\n",
    "    \n",
    "config = RunnableConfig(max_concurrency=100)\n",
    "chat = ChatDeepInfra(model=\"deepseek-ai/DeepSeek-V3.1\")\n",
    "output_model = chat.batch(messages, config=config)\n",
    "output = [res.content for res in output_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1fe859cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"[('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', 0.5), ('service_sentiment', 0.7), ('atmosphere_sentiment', 0.6)]\", \"[('food_sentiment', 0.0), ('service_sentiment', 0.5), ('atmosphere_sentiment', 1.0)]\", \"[('food_sentiment', None), ('service_sentiment', -1.0), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', 1.0), ('service_sentiment', None), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', 1.0), ('service_sentiment', None), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', None), ('service_sentiment', None), ('atmosphere_sentiment', 0.8)]\", \"[('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmosphere_sentiment', 1.0)]\", \"[('food_sentiment', None), ('service_sentiment', -0.5), ('atmosphere_sentiment', 0.7)]\", \"[('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmosphere_sentiment', 1.0)]\", \"[('food_sentiment', None), ('service_sentiment', None), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', 1.0), ('service_sentiment', None), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', None), ('service_sentiment', 1.0), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', 0.8), ('service_sentiment', None), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', 0.8), ('service_sentiment', 0.6), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', None), ('service_sentiment', None), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', None), ('service_sentiment', None), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmosphere_sentiment', 1.0)]\", \"[('food_sentiment', None), ('service_sentiment', None), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', None), ('service_sentiment', 0.5), ('atmosphere_sentiment', 0.7)]\", \"[('food_sentiment', None), ('service_sentiment', 0.5), ('atmosphere_sentiment', 0.5)]\", \"[('food_sentiment', -1.0), ('service_sentiment', None), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', None), ('service_sentiment', 0.5), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', None), ('service_sentiment', -1.0), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', 0.9), ('service_sentiment', 0.9), ('atmosphere_sentiment', -0.3)]\", \"[('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmosphere_sentiment', 1.0)]\", \"[('food_sentiment', 0.8), ('service_sentiment', 0.9), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', 0.8), ('service_sentiment', 1.0), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', -1.0), ('service_sentiment', -1.0), ('atmosphere_sentiment', 1.0)]\", \"[('food_sentiment', None), ('service_sentiment', 0.5), ('atmosphere_sentiment', 1.0)]\", \"[('food_sentiment', None), ('service_sentiment', None), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', -1.0), ('service_sentiment', -1.0), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', None), ('service_sentiment', 1.0), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', 1.0), ('service_sentiment', 0.8), ('atmosphere_sentiment', 0.8)]\", \"[('food_sentiment', -0.5), ('service_sentiment', None), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', 1.0), ('service_sentiment', 0.8), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmosphere_sentiment', 1.0)]\", \"[('food_sentiment', 1.0), ('service_sentiment', None), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmosphere_sentiment', 1.0)]\", \"[('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', None), ('service_sentiment', None), ('atmosphere_sentiment', -0.5)]\", \"[('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmosphere_sentiment', 1.0)]\", \"[('food_sentiment', None), ('service_sentiment', 1.0), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', None), ('service_sentiment', -1.0), ('atmosphere_sentiment', -1.0)]\", \"[('food_sentiment', 1.0), ('service_sentiment', 0.8), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', 1.0), ('service_sentiment', None), ('atmosphere_sentiment', 1.0)]\", \"[('food_sentiment', 1.0), ('service_sentiment', None), ('atmosphere_sentiment', 1.0)]\", \"[('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', 1.0), ('service_sentiment', None), ('atmosphere_sentiment', None)]\", \"[('food_sentiment', None), ('service_sentiment', None), ('atmosphere_sentiment', None)]\"]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7802db7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom mse: 0.08307692307692305\n",
      "none_accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "new_list = []\n",
    "for el in output:\n",
    "    new_list.append([eval(el)[0][1], eval(el)[1][1], eval(el)[2][1]])\n",
    "array_list = np.array(new_list, dtype=float)\n",
    "array_gold = gold_df_dev[['food_sentiment', 'service_sentiment','atmosphere_sentiment']].to_numpy()\n",
    "custom_evaluation(array_gold, array_list)\n",
    "#print(list(zip(gold_df_dev.review, output)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c39a18",
   "metadata": {},
   "source": [
    "## Version 5: Finetune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61e4687f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "\u001b[K     |████████████████████████████████| 494 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-21.0.0-cp39-cp39-macosx_12_0_arm64.whl (31.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 31.2 MB 996 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /opt/miniconda3/lib/python3.9/site-packages (from datasets) (2024.6.1)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/lib/python3.9/site-packages (from datasets) (25.0)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[K     |████████████████████████████████| 116 kB 18.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/miniconda3/lib/python3.9/site-packages (from datasets) (2.0.0)\n",
      "Collecting tqdm>=4.66.3\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multiprocess<0.70.17\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.24.0 in /opt/miniconda3/lib/python3.9/site-packages (from datasets) (0.34.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/miniconda3/lib/python3.9/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/lib/python3.9/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/lib/python3.9/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/lib/python3.9/site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/miniconda3/lib/python3.9/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/miniconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/miniconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/miniconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/miniconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/miniconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /opt/miniconda3/lib/python3.9/site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/miniconda3/lib/python3.9/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (1.26.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/miniconda3/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: tqdm, dill, xxhash, pyarrow, multiprocess, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.0\n",
      "    Uninstalling tqdm-4.64.0:\n",
      "      Successfully uninstalled tqdm-4.64.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy 3.5.2 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.8.2 which is incompatible.\u001b[0m\n",
      "Successfully installed datasets-4.0.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-21.0.0 tqdm-4.67.1 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b703f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  labels\n",
      "0     La atención al cliente no es la correcta y la ...     0.0\n",
      "1     Hemos ido a cenar y la verdad es que nos ha en...     1.0\n",
      "2     Büyük porsiyonlar anca bir normal porsiyon old...     0.0\n",
      "3     Great sushi experience. Nice value. Unique app...     1.0\n",
      "4     Fethipaşa korusunun içinde bulunan manzarasına...     0.0\n",
      "...                                                 ...     ...\n",
      "4656  En nog heel lekker gegeten ook! We volgden de ...     1.0\n",
      "4657  Занесло нас сюда огромное желание поесть мясо,...     0.0\n",
      "4658  Un buen restaurante relación calidad-precio mu...     0.0\n",
      "4659  Побывали с друзьями в Малевиче. Слухов было мн...     0.0\n",
      "4660  Un restaurante como la copa de un pino. Gran d...     1.0\n",
      "\n",
      "[4661 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████| 4194/4194 [00:00<00:00, 10230.07 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████| 467/467 [00:00<00:00, 7265.44 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import math\n",
    "\n",
    "# Load IMDb dataset\n",
    "data_bert = semval_df[['review','food_sentiment']].copy()\n",
    "data_bert =  data_bert.fillna(0)\n",
    "data_bert = data_bert.rename(columns={\"review\": \"text\", \"food_sentiment\": \"labels\"})\n",
    "print(data_bert)\n",
    "dataset = Dataset.from_pandas(data_bert)\n",
    "dataset = dataset.train_test_split(test_size=0.1) \n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the tokenizer for a pretrained BERT model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", token='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')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7688e847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='789' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  4/789 00:40 < 4:23:31, 0.05 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG14GFamilyCommandBuffer: 0x11bf5f1d0>\n",
      "    label = <none> \n",
      "    device = <AGXG14GDevice: 0x13cf1ec00>\n",
      "        name = Apple M2 \n",
      "    commandQueue = <AGXG14GFamilyCommandQueue: 0x33280a400>\n",
      "        label = <none> \n",
      "        device = <AGXG14GDevice: 0x13cf1ec00>\n",
      "            name = Apple M2 \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG14GFamilyCommandBuffer: 0x11e2d4010>\n",
      "    label = <none> \n",
      "    device = <AGXG14GDevice: 0x13cf1ec00>\n",
      "        name = Apple M2 \n",
      "    commandQueue = <AGXG14GFamilyCommandQueue: 0x33280a400>\n",
      "        label = <none> \n",
      "        device = <AGXG14GDevice: 0x13cf1ec00>\n",
      "            name = Apple M2 \n",
      "    retainedReferences = 1\n",
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG14GFamilyCommandBuffer: 0x14e6ef2a0>\n",
      "    label = <none> \n",
      "    device = <AGXG14GDevice: 0x13cf1ec00>\n",
      "        name = Apple M2 \n",
      "    commandQueue = <AGXG14GFamilyCommandQueue: 0x33280a400>\n",
      "        label = <none> \n",
      "        device = <AGXG14GDevice: 0x13cf1ec00>\n",
      "            name = Apple M2 \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 29\u001b[0m\n\u001b[1;32m     12\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m                                   logging_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m                                   per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m                                   load_best_model_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     20\u001b[0m                                   )\n\u001b[1;32m     22\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     23\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     24\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:2238\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2236\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2239\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:2533\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2531\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2532\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2533\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2534\u001b[0m \u001b[38;5;66;03m# Store the number of batches for current gradient accumulation\u001b[39;00m\n\u001b[1;32m   2535\u001b[0m \u001b[38;5;66;03m# This is used to correctly scale the loss when the last accumulation step has fewer batches\u001b[39;00m\n\u001b[1;32m   2536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_gradient_accumulation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/transformers/trainer.py:5355\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches, device)\u001b[0m\n\u001b[1;32m   5353\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5354\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5355\u001b[0m         batch_samples\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   5356\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5357\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/accelerate/data_loader.py:579\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_blocking)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state_dict()\n\u001b[0;32m--> 579\u001b[0m next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    740\u001b[0m ):\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:790\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    789\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    792\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py:2863\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m   2862\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2863\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2864\u001b[0m     n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[1;32m   2865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py:2859\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolars\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2858\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Column(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[0;32m-> 2859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py:2840\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2838\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   2839\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2840\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43mquery_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2841\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[1;32m   2842\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[1;32m   2843\u001b[0m )\n\u001b[1;32m   2844\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py:614\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# Query the main table\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 614\u001b[0m     pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43m_query_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    616\u001b[0m     pa_subtable \u001b[38;5;241m=\u001b[39m _query_table_with_indices_mapping(table, key, indices\u001b[38;5;241m=\u001b[39mindices)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py:99\u001b[0m, in \u001b[0;36m_query_table\u001b[0;34m(table, key)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39mtable\u001b[38;5;241m.\u001b[39mslice(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# don't use pyarrow.Table.take even for pyarrow >=1.0 (see https://issues.apache.org/jira/browse/ARROW-9773)\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m _raise_bad_key_type(key)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/datasets/table.py:121\u001b[0m, in \u001b[0;36mIndexedTableMixin.fast_gather\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndices must be non-empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    120\u001b[0m batch_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msearchsorted(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offsets, indices, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_batches\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batches\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_offsets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=1, token='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')\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
    "                                  logging_strategy=\"epoch\",\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  per_device_eval_batch_size=16,\n",
    "                                  num_train_epochs=3,\n",
    "                                  save_total_limit = 2,\n",
    "                                  save_strategy = 'no',\n",
    "                                  load_best_model_at_end=False\n",
    "                                  )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b292612",
   "metadata": {},
   "source": [
    "## Appendix 1: Failed local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "029c5c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "What is the capital of France.<|im_end|>\n",
      "\n",
      "<|im_start|>user\n",
      "What is the capital of France.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The capital of France is Paris, officially known as the City of Light. It is the seat of the French government, the national capital, and the capital of the Île-de-France region.\n",
      "\n",
      "Paris is\n"
     ]
    }
   ],
   "source": [
    "# pip install transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "checkpoint = \"HuggingFaceTB/SmolLM-360M-Instruct\"\n",
    "\n",
    "device = \"cpu\" # for GPU usage or \"cpu\" for CPU usage\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, token='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')\n",
    "# for multiple GPUs install accelerate and do `model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\")`\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, token='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').to(device)\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is the capital of France.\"}]\n",
    "input_text=tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "print(input_text)\n",
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs, max_new_tokens=50, temperature=0.2, top_p=0.9, do_sample=True)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "48870ec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 16\u001b[0m\n\u001b[1;32m     11\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:text},\n\u001b[1;32m     13\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:sentence},\n\u001b[1;32m     14\u001b[0m     ]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#messages = [{\"role\": \"user\", \"content\": \"What is the capital of France.\"}]\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     input_text\u001b[38;5;241m=\u001b[39m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#print(input_text)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(input_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "text = \"Please perform Aspect-Based Sentiment Classification task on google maps reviews. \\\n",
    "Given a review, classify each (sentiment, rating) pair. \\\n",
    "Sentiments are ['sentiment_food', 'sentiment_ambiance', 'sentiment_service'] \\\n",
    ", and ratings should be selected as a floating point number from -1 to 1. \\\n",
    "If a sentiment does not apply, its rating should be 0. This also applies to short reviews like 'Great!'\\\n",
    "Always return a valid python list of tuples containing a \\\n",
    "string in single quotes and a float for each sentiment. Please return python list only, \\\n",
    "without any other comments or texts.\"\n",
    "output2 = []\n",
    "for sentence in sentences.review.to_list()[::-1]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\":text},\n",
    "        {\"role\": \"user\", \"content\":sentence},\n",
    "    ]\n",
    "#messages = [{\"role\": \"user\", \"content\": \"What is the capital of France.\"}]\n",
    "    input_text=tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    #print(input_text)\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(inputs, max_new_tokens=50, temperature=0.2, top_p=0.9, do_sample=False)\n",
    "    print('output:', tokenizer.decode(outputs[0]))\n",
    "\n",
    "#output2.append(model.invoke(messages).content)\n",
    "#print(sentence, output2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d3457dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have eaten at Saul, many times, the food is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Went on a 3 day oyster binge, with Fish bringi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Every time in New York I make it a point to vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We ate outside at Haru's Sake bar because Haru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>This small Astoria souvlaki spot makes what ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>I was here a few weeks back and we had the wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>After passing by this restaurant for sometime ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Having hunted around for a quiet, romantic, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Suan is a great place that I often take my fri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews\n",
       "0    Judging from previous posts this used to be a ...\n",
       "1    I have eaten at Saul, many times, the food is ...\n",
       "2    Went on a 3 day oyster binge, with Fish bringi...\n",
       "3    Every time in New York I make it a point to vi...\n",
       "4    We ate outside at Haru's Sake bar because Haru...\n",
       "..                                                 ...\n",
       "330  This small Astoria souvlaki spot makes what ma...\n",
       "331  I was here a few weeks back and we had the wor...\n",
       "332  After passing by this restaurant for sometime ...\n",
       "333  Having hunted around for a quiet, romantic, ye...\n",
       "334  Suan is a great place that I often take my fri...\n",
       "\n",
       "[335 rows x 1 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "semval_data = pd.DataFrame()\n",
    "\n",
    "tree = ET.parse('data/semeval/ABSA16_Restaurants_Train_English_SB2.xml')\n",
    "root = tree.getroot()\n",
    " \n",
    "reviews = []\n",
    "for review in root.findall('Review'):\n",
    "    for sentences in review.findall('sentences'):\n",
    "        full_review = ''\n",
    "        for sentence in sentences.findall('sentence'):\n",
    "            full_review += sentence.find('text').text.replace(\"\\'\", \"'\") + ' '\n",
    "    #print(full_review)\n",
    "    reviews.append(full_review)\n",
    "    for Opinions in review.find('Opinions'):\n",
    "        for opinion in Opinions.findall('Opinion'):\n",
    "            print(opinion.find('category'))\n",
    "        break\n",
    "semval_data['reviews'] = reviews\n",
    "semval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21616600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>google_maps_profile_id</th>\n",
       "      <th>review</th>\n",
       "      <th>food_sentiment</th>\n",
       "      <th>service_sentiment</th>\n",
       "      <th>atmoshpere_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>624932</td>\n",
       "      <td>Sehr leckeres Essen... Personal ist zudem sehr...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624932</td>\n",
       "      <td>Auf 800 m auf der Sonnenterrasse Heiden treffe...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>624932</td>\n",
       "      <td>Sehr feines Libanesisches Essen. Ein Hauch vom...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>624932</td>\n",
       "      <td>Gutes Essen</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>624932</td>\n",
       "      <td>Toller Geheimtipp.\\nNicht viel Platz dafür ein...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>624932</td>\n",
       "      <td>Great food and nice friendly familiar service.</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>624932</td>\n",
       "      <td>Einfach mega lecker. Ich komme gerne wieder!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>624932</td>\n",
       "      <td>absolut top! Wunderbares authentisches Essen, ...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>624932</td>\n",
       "      <td>\"**Ein absolutes Highlight für Liebhaber der l...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>624932</td>\n",
       "      <td>Sehr gute Küche. Genügend Zeit nehmen und geni...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   google_maps_profile_id                                             review   \n",
       "0                  624932  Sehr leckeres Essen... Personal ist zudem sehr...  \\\n",
       "1                  624932  Auf 800 m auf der Sonnenterrasse Heiden treffe...   \n",
       "2                  624932  Sehr feines Libanesisches Essen. Ein Hauch vom...   \n",
       "3                  624932                                        Gutes Essen   \n",
       "4                  624932  Toller Geheimtipp.\\nNicht viel Platz dafür ein...   \n",
       "5                  624932     Great food and nice friendly familiar service.   \n",
       "6                  624932       Einfach mega lecker. Ich komme gerne wieder!   \n",
       "7                  624932  absolut top! Wunderbares authentisches Essen, ...   \n",
       "8                  624932  \"**Ein absolutes Highlight für Liebhaber der l...   \n",
       "9                  624932  Sehr gute Küche. Genügend Zeit nehmen und geni...   \n",
       "\n",
       "   food_sentiment  service_sentiment  atmoshpere_sentiment  \n",
       "0             0.9                0.7                   NaN  \n",
       "1             0.9                0.7                   0.8  \n",
       "2             0.7                NaN                   0.5  \n",
       "3             0.6                NaN                   NaN  \n",
       "4             0.8                0.4                  -0.2  \n",
       "5             0.8                0.5                   NaN  \n",
       "6             1.0                NaN                   NaN  \n",
       "7             0.8                0.4                   0.7  \n",
       "8             1.0                0.8                   0.4  \n",
       "9             0.7                NaN                   NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df = sentences.iloc[:10].copy()\n",
    "    \n",
    "food_gold = [0.9, 0.9, 0.7, 0.6, 0.8, 0.8, 1, 0.8, 1, 0.7]\n",
    "service_gold = [0.7, 0.7, None, None, 0.4, 0.5, None, 0.4, 0.8, None]\n",
    "atmosphere_gold = [None, 0.8, 0.5, None, -0.2, None, None, 0.7, 0.4, None]\n",
    "\n",
    "gold_df['food_sentiment'] = food_gold\n",
    "gold_df['service_sentiment'] = service_gold\n",
    "gold_df['atmoshpere_sentiment'] = atmosphere_gold\n",
    "\n",
    "gold_df\n",
    "\n",
    "# TODO: Get better sample balance:\n",
    "# - 100 datapoints\n",
    "# - same distribution of languages or equal distribution of languages\n",
    "# - equal distribution of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a1104",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Please perform Aspect-Based Sentiment Classification task on google maps reviews. \\\n",
    "Given a review, output a python list with three numbers of type float or None, corresponding to the rating of each sentiment for that review. \\\n",
    "Sentiments are ['food_sentiment', 'service_sentiment', 'atmosphere_sentiment']. \\\n",
    "'food_sentiment' should answer: What does the review say about how good the food was? \\\n",
    "'service_sentiment' should answer: What does the review say about how good the service was? \\\n",
    "'atmosphere_sentiment' should answer: What does the review say about how good the atmoshpere was? \\\n",
    "The ratings should be selected as a floating point number from -1 to 1. Where 1 means excellent, above all expectations, and -1 means the worst ever experienced. \\\n",
    "If a sentiment does not apply, its rating should be the python Value 'None'. \\\n",
    "This also applies to short reviews like 'Great!'.\\\n",
    "Always return a valid python list of tuples containing a string in single quotes and a float for each sentiment.\\\n",
    "Please return python list only, without any other comments or texts.\\\n",
    "Here one example: Input: 'The food was good, the atmosphere was not.' Output: '[0.8, None, -0.4]'\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
