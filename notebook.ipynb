{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0150c5f",
   "metadata": {},
   "source": [
    "# Cohaga DS Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da765fe",
   "metadata": {},
   "source": [
    "## Data import and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4001df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a99c99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of       google_maps_profile_id  review_id   \n",
      "0                     624932    6386691  \\\n",
      "1                     624932    6386692   \n",
      "2                     624932    6386693   \n",
      "3                     624932    6386694   \n",
      "4                     624932    6386695   \n",
      "...                      ...        ...   \n",
      "9995                  151741    3027281   \n",
      "9996                  151741    3027284   \n",
      "9997                  151741    3027288   \n",
      "9998                  151741    3027291   \n",
      "9999                  151741    3027293   \n",
      "\n",
      "                                                 review  rating   \n",
      "0     Sehr leckeres Essen... Personal ist zudem sehr...       5  \\\n",
      "1     Auf 800 m auf der Sonnenterrasse Heiden treffe...       5   \n",
      "2     Sehr feines Libanesisches Essen. Ein Hauch vom...       5   \n",
      "3                                           Gutes Essen       5   \n",
      "4     Toller Geheimtipp.\\nNicht viel Platz daf√ºr ein...       5   \n",
      "...                                                 ...     ...   \n",
      "9995  Pas assez d'intimit√© quand on est seul sinon m...       3   \n",
      "9996  Accueil tres bien\\nService souriant\\nTres prop...       5   \n",
      "9997  La cuisine d'Alain Meystre est toujours aussi ...       5   \n",
      "9998  Nous √©tions c√¥te brasserie,pour un  menu surpr...       5   \n",
      "9999             Tr√®s bon accueil et tr√®s bonne cuisine       4   \n",
      "\n",
      "                                             source_url  \n",
      "0     https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "1     https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "2     https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "3     https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "4     https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "...                                                 ...  \n",
      "9995  https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "9996  https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "9997  https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "9998  https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "9999  https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "\n",
      "[10000 rows x 5 columns]>\n",
      "[RangeIndex(start=0, stop=10000, step=1), Index(['google_maps_profile_id', 'review_id', 'review', 'rating',\n",
      "       'source_url'],\n",
      "      dtype='object')]\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"data/task_1_google_maps_comments.csv\")\n",
    "print(data_df.info)\n",
    "print(data_df.axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd85efba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   google_maps_profile_id  10000 non-null  int64 \n",
      " 1   review                  10000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "sentences = data_df.loc[:, ['google_maps_profile_id', 'review']]\n",
    "sentences.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870e3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Add review length analysis\n",
    "# TODO analyze number of reviews per rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e832c41",
   "metadata": {},
   "source": [
    "###¬†Check languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42faeb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "model = fasttext.load_model('models/lid.176.bin')\n",
    "lang_list = [model.predict(review.replace('\\n', ' '), k=1)[0][0] for review in sentences.review]\n",
    "sentences['language'] = lang_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1e2de99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__label__hu', '__label__cs', '__label__sv', '__label__en', '__label__la', '__label__it', '__label__th', '__label__pl', '__label__fi', '__label__sh', '__label__nds', '__label__ar', '__label__bg', '__label__ko', '__label__da', '__label__sl', '__label__oc', '__label__ru', '__label__nn', '__label__eu', '__label__tr', '__label__vi', '__label__bn', '__label__ca', '__label__es', '__label__fr', '__label__de', '__label__ro', '__label__ja', '__label__fa', '__label__no', '__label__ia', '__label__he', '__label__sk', '__label__pt', '__label__ast', '__label__id', '__label__sr', '__label__hr', '__label__uk', '__label__el', '__label__gl', '__label__ms', '__label__nl', '__label__mn', '__label__br', '__label__eo', '__label__zh', '__label__als', '__label__ceb'}\n",
      "__label__hu Sz√©p hangulatos helyen, finom √©telek. Maxim√°lis vend√©gl√°t√°s.\n",
      "__label__cs V≈°e bylo v√Ωborn√©\n",
      "__label__sv üëå\n",
      "__label__en Great food and nice friendly familiar service.\n",
      "__label__la Tiptoppüëåüòç\n",
      "__label__it Panorama stupendo, servizio cortese e professionale . La cucina √® curata e i piatti appagano l'occhio e la gola!!!!! Ci ritorner√≤ quanto prima!!!\n",
      "__label__th ‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏®‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏° ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢‡∏°‡∏≤‡∏Å‡πÜ‡πÜ‡πÜ\n",
      "__label__pl Cudny widok, pyszne szwajcarskie piwko i winko\n",
      "__label__fi Terassi mahtavien vuorten vieress√§ ja palvelu great!!üòÄ\n",
      "__label__sh Tip top\n",
      "__label__nds Sehr leckeres Essen!üòÄ‚ù§Ô∏è\n",
      "__label__ar ŸÖŸÉÿßŸÜ Ÿäÿ≥ÿ™ÿ≠ŸÇ ÿßŸÑÿ≤Ÿäÿßÿ±ÿ© ÿßŸÑŸÖŸàŸÇÿπ ŸÖŸÇÿßÿ®ŸÑ ÿßŸÑÿ®ÿ≠Ÿäÿ±ÿ©\n",
      "__label__bg –í–∫—É—Å–Ω–æ.\n",
      "__label__ko ÏïÑÎ¶ÑÎã§Ïö¥Í≤ΩÏπòÏóêÏÑúÏ∞®ÌïúÏûî\n",
      "__label__da Hyggelig after ski med flott beliggenhet. Akkurat n√•r du kommer ned fra en mega-lang nedkj√∏ling fra fjellet og bena er passe gele. Da er det godt med en √∏l üòä\n",
      "__label__sl Guet gsiii\n",
      "__label__oc Mmmmmh...\n",
      "__label__ru –í–∏–¥ —Å —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞, –∑–∞–≤–æ—Ä–∞–∂–∏–≤–∞–µ—Ç. –ö—É—Ö–Ω—è —Ç–æ–∂–µ –æ—Ç–ª–∏—á–Ω–∞—è, —à–≤–µ–π—Ü–∞—Ä—Å–∫–∞—è.\n",
      "–¶–µ–Ω—ã —Ç–∞–∫ –∂–µ, –Ω–µ —Å–∞–º—ã–µ –±–æ–ª—å—à–∏–µ –≤ –®–≤–µ–π—Ü–∞—Ä–∏–∏.\n",
      "__label__nn Perfekt üëçüëçüëç\n",
      "__label__eu S beste vo de w√§lt üòòüòç\n",
      "__label__tr Cok basarili keyifli lezzetli manzarasi harika bir restorant g√ºlery√ºzl√º servis\n",
      "__label__vi Un saluto a Giov√† :D\n",
      "__label__bn Mega fein gsi\n",
      "__label__ca Vistes impressionants. Bon menjar i bon servei\n",
      "__label__es Muy recomendable üëå üëç\n",
      "__label__fr Sehr lecker\n",
      "__label__de Sehr leckeres Essen... Personal ist zudem sehr freundlich.\n",
      "__label__ro Patronul foarte rau\n",
      "__label__ja „Çπ„Éç„Ç¨„Åã„ÇâÊ≠©„ÅÑ„Å¶ÂæÄÂæ©„Åó„Åæ„Åó„Åü„Åå„ÄÅÂùÇ„Åå„Å®„Çì„Åß„ÇÇ„Å™„Åè„Åç„Å§„Åã„Å£„Åü„Åß„ÅôÁ¨ë„ÄÄ„Éì„Éº„É´„ÅØ6CHFüòä„ÄÄÊ∏ÖÊΩî„ÅßÈõ∞Âõ≤Ê∞ó„ÅåËâØ„ÅÑÁ¥†Êïµ„Å™„É¨„Çπ„Éà„É©„É≥„Åß„Åó„ÅüÔºÅ\n",
      "__label__fa ÿÆŸàÿ® ÿ®ŸàÿØ\n",
      "__label__no Placut\n",
      "__label__ia A repetir a visita! ‚ù§Ô∏è‚úåÔ∏è‚úåÔ∏è\n",
      "__label__he ◊û◊ß◊ï◊ù ◊û◊¢◊ï◊ú◊î ◊ú◊¢◊¶◊ô◊®◊î ◊û◊ï◊ú ◊†◊ï◊£ ◊û◊ò◊ï◊®◊£.\n",
      "__label__sk Pekn√° miestna re≈°taur√°cia v alpskom ≈°t√Ωle. Pizza super.Ceny samozrejme na √∫rovni ≈°vajƒçiarskych √Ålp üòÅüòÅ\n",
      "__label__pt Atendimento impec√°vel e excelente variedade de comida libanesa.\n",
      "__label__ast Wunderbares Ostermen√ºe.\n",
      "__label__id Tiptop\n",
      "__label__sr Izuzetno ƒçisto, izuzetno ljubazno osoblje, izuzetno sve≈æa i ukusna hrana, domaƒáinski u pravom smislu te reƒçi.\n",
      "Lidija Stefanoviƒá, Waltenschwil\n",
      "__label__hr Sasvim pristojno. Omjer cijene i kvalitete.\n",
      "__label__uk –°–º–∞—á–Ω–æ, —à–≤–∏–¥–∫–æ, –ø—Ä–∏–≤—ñ—Ç–Ω–æ\n",
      "__label__el ŒïŒØŒΩŒ±Œπ œÑŒ≠ŒªŒµŒπŒø. üòç\n",
      "__label__gl Genial:)\n",
      "__label__ms Guter Kebap\n",
      "__label__nl Top!\n",
      "__label__mn Super . –°–∞–π—Ö–∞–Ω –º—ç–¥—Ä—ç–º–∂ “Ø—Ö—Ä–∏–π–Ω –º–∞—Ö –∞–¥—É—É–Ω—ã –º–∞—Ö –∑–∞–≥–∞—Å –±“Ø–≥–¥ –æ—Ä—á–∏–Ω —Å–∞–π—Ö–∞–Ω —É—Ä–ª–∞–≥–∏–π–Ω –±“Ø—Ç—ç—ç–ª “Ø—Ö—ç—Ä –º–∞–Ω–¥—Ç—É–≥–∞–π\n",
      "__label__br zebra burger>\n",
      "__label__eo Paradiso puro\n",
      "__label__zh üòÄüòÄüòÄ\n",
      "__label__als Dank√§ viilmal f√ºr dii fr√º√ºndlich bedienig... Esch sch√∂n gsi bi √∂ui üòè\n",
      "__label__ceb üòÄüòÑüòÑüòÑ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "language\n",
       "__label__de     5808\n",
       "__label__en     1728\n",
       "__label__fr      991\n",
       "__label__it      951\n",
       "__label__es       99\n",
       "__label__nl       62\n",
       "__label__pt       52\n",
       "__label__ar       51\n",
       "__label__pl       29\n",
       "__label__tr       24\n",
       "__label__als      22\n",
       "__label__ko       20\n",
       "__label__sv       17\n",
       "__label__ru       16\n",
       "__label__zh       15\n",
       "__label__ja       14\n",
       "__label__hu        8\n",
       "__label__da        7\n",
       "__label__cs        6\n",
       "__label__fi        6\n",
       "__label__ro        6\n",
       "__label__sl        5\n",
       "__label__ca        5\n",
       "__label__ceb       5\n",
       "__label__no        5\n",
       "__label__vi        4\n",
       "__label__bg        4\n",
       "__label__id        4\n",
       "__label__uk        3\n",
       "__label__eo        3\n",
       "__label__he        3\n",
       "__label__hr        3\n",
       "__label__sr        2\n",
       "__label__oc        2\n",
       "__label__th        2\n",
       "__label__ms        2\n",
       "__label__el        2\n",
       "__label__sk        2\n",
       "__label__fa        1\n",
       "__label__br        1\n",
       "__label__ast       1\n",
       "__label__nds       1\n",
       "__label__gl        1\n",
       "__label__mn        1\n",
       "__label__nn        1\n",
       "__label__eu        1\n",
       "__label__la        1\n",
       "__label__ia        1\n",
       "__label__bn        1\n",
       "__label__sh        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(set(lang_list))\n",
    "for l in set(lang_list):\n",
    "    print(l, sentences[sentences.language == l].iloc[0].review)\n",
    "sentences.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65cd385",
   "metadata": {},
   "source": [
    "###¬†Self-rated Gold-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21616600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>google_maps_profile_id</th>\n",
       "      <th>review</th>\n",
       "      <th>language</th>\n",
       "      <th>food_sentiment</th>\n",
       "      <th>service_sentiment</th>\n",
       "      <th>atmoshpere_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>624932</td>\n",
       "      <td>Sehr leckeres Essen... Personal ist zudem sehr...</td>\n",
       "      <td>__label__de</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624932</td>\n",
       "      <td>Auf 800 m auf der Sonnenterrasse Heiden treffe...</td>\n",
       "      <td>__label__de</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>624932</td>\n",
       "      <td>Sehr feines Libanesisches Essen. Ein Hauch vom...</td>\n",
       "      <td>__label__de</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>624932</td>\n",
       "      <td>Gutes Essen</td>\n",
       "      <td>__label__de</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>624932</td>\n",
       "      <td>Toller Geheimtipp.\\nNicht viel Platz daf√ºr ein...</td>\n",
       "      <td>__label__de</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>624932</td>\n",
       "      <td>Great food and nice friendly familiar service.</td>\n",
       "      <td>__label__en</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>624932</td>\n",
       "      <td>Einfach mega lecker. Ich komme gerne wieder!</td>\n",
       "      <td>__label__de</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>624932</td>\n",
       "      <td>absolut top! Wunderbares authentisches Essen, ...</td>\n",
       "      <td>__label__de</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>624932</td>\n",
       "      <td>\"**Ein absolutes Highlight f√ºr Liebhaber der l...</td>\n",
       "      <td>__label__de</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>624932</td>\n",
       "      <td>Sehr gute K√ºche. Gen√ºgend Zeit nehmen und geni...</td>\n",
       "      <td>__label__de</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   google_maps_profile_id                                             review   \n",
       "0                  624932  Sehr leckeres Essen... Personal ist zudem sehr...  \\\n",
       "1                  624932  Auf 800 m auf der Sonnenterrasse Heiden treffe...   \n",
       "2                  624932  Sehr feines Libanesisches Essen. Ein Hauch vom...   \n",
       "3                  624932                                        Gutes Essen   \n",
       "4                  624932  Toller Geheimtipp.\\nNicht viel Platz daf√ºr ein...   \n",
       "5                  624932     Great food and nice friendly familiar service.   \n",
       "6                  624932       Einfach mega lecker. Ich komme gerne wieder!   \n",
       "7                  624932  absolut top! Wunderbares authentisches Essen, ...   \n",
       "8                  624932  \"**Ein absolutes Highlight f√ºr Liebhaber der l...   \n",
       "9                  624932  Sehr gute K√ºche. Gen√ºgend Zeit nehmen und geni...   \n",
       "\n",
       "      language  food_sentiment  service_sentiment  atmoshpere_sentiment  \n",
       "0  __label__de             0.9                0.7                   NaN  \n",
       "1  __label__de             0.9                0.7                   0.8  \n",
       "2  __label__de             0.7                NaN                   0.5  \n",
       "3  __label__de             0.6                NaN                   NaN  \n",
       "4  __label__de             0.8                0.4                  -0.2  \n",
       "5  __label__en             0.8                0.5                   NaN  \n",
       "6  __label__de             1.0                NaN                   NaN  \n",
       "7  __label__de             0.8                0.4                   0.7  \n",
       "8  __label__de             1.0                0.8                   0.4  \n",
       "9  __label__de             0.7                NaN                   NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df = sentences.iloc[:10].copy()\n",
    "    \n",
    "food_gold = [0.9, 0.9, 0.7, 0.6, 0.8, 0.8, 1, 0.8, 1, 0.7]\n",
    "service_gold = [0.7, 0.7, None, None, 0.4, 0.5, None, 0.4, 0.8, None]\n",
    "atmosphere_gold = [None, 0.8, 0.5, None, -0.2, None, None, 0.7, 0.4, None]\n",
    "\n",
    "gold_df['food_sentiment'] = food_gold\n",
    "gold_df['service_sentiment'] = service_gold\n",
    "gold_df['atmoshpere_sentiment'] = atmosphere_gold\n",
    "\n",
    "gold_df\n",
    "\n",
    "# TODO: Get better sample balance:\n",
    "# - 100 datapoints\n",
    "# - same distribution of languages or equal distribution of languages\n",
    "# - equal distribution of ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d4a7a5",
   "metadata": {},
   "source": [
    "### Public Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "285f7825",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSA16_Restaurants_Train_English_SB2.xml\n",
      "restaurants_dutch_training_textlevel.xml\n",
      "restaurant_tain_text_level_final.xml\n",
      "SemEval-2016ABSA Restaurants-Spanish_Train_Subtask2.xml\n",
      "se16_ru_rest_train_task2.xml\n",
      "                                            review_text food_sentiment   \n",
      "0     Judging from previous posts this used to be a ...       negative  \\\n",
      "1     I have eaten at Saul, many times, the food is ...       positive   \n",
      "2     Went on a 3 day oyster binge, with Fish bringi...       positive   \n",
      "3     Every time in New York I make it a point to vi...       positive   \n",
      "4     We ate outside at Haru's Sake bar because Haru...       positive   \n",
      "...                                                 ...            ...   \n",
      "1859  –°–µ–≥–æ–¥–Ω—è –±—ã–ª–∏ –∫–æ–º–ø–∞–Ω–∏–µ–π –∏–∑ 4—Ö —á–µ–ª–æ–≤–µ–∫, –±—ã–ª–∏ —É–∂–µ...       positive   \n",
      "1860  –í—á–µ—Ä–∞ –æ—Ç–º–µ—á–∞–ª–∏ –¥–µ–Ω—å —Ä–æ–∂–¥–µ–Ω–∏—è –≤ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–µ, —Å—Ö–æ–¥...       positive   \n",
      "1861  –û—á–µ–Ω—å –ø—Ä–∏—è—Ç–Ω–æ–µ —É—é—Ç–Ω–æ–µ –º–µ—Å—Ç–µ—á–∫–æ. –•–æ—Ä–æ—à–∏–π —Ü–µ–Ω–Ω–∏–∫...       conflict   \n",
      "1862  –í –ø—Ä–æ—à–ª—É—é —Å—É–±–±–æ—Ç—É –ø–æ—Å–µ—Ç–∏–ª–∏ —Å –¥—Ä—É–∑—å—è–º–∏ —ç—Ç–æ –∑–∞–≤–µ...       positive   \n",
      "1863  –ó–∞—à–ª–∏ –≤\"–∞–ø–ø–µ—Ç–∏—Ç\" —Å–ª—É—á–∞–π–Ω–æ. –ù–µ —Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ,—á—Ç–æ...       positive   \n",
      "\n",
      "     service_sentiment atmosphere_sentiment  \n",
      "0             negative                 None  \n",
      "1                 None                 None  \n",
      "2             positive                 None  \n",
      "3             positive             positive  \n",
      "4             positive                 None  \n",
      "...                ...                  ...  \n",
      "1859          positive             conflict  \n",
      "1860          positive             positive  \n",
      "1861          conflict             conflict  \n",
      "1862          positive             conflict  \n",
      "1863          positive                 None  \n",
      "\n",
      "[1864 rows x 4 columns]\n",
      "ABSA16_Restaurants_Train_SB1_v2.xml\n",
      "restaurants_dutch_training.xml\n",
      "reviews.xml\n",
      "SemEval-2016ABSA Restaurants-Spanish_Train_Subtask1.xml\n",
      "se16_ru_rest_train.xml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>food_sentiment</th>\n",
       "      <th>service_sentiment</th>\n",
       "      <th>atmosphere_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have eaten at Saul, many times, the food is ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Went on a 3 day oyster binge, with Fish bringi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Every time in New York I make it a point to vi...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We ate outside at Haru's Sake bar because Haru...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>–ë—ã–ª–∏ –≤—á–µ—Ä–∞ —Å –ø–æ–¥—Ä—É–≥–æ–π –≤ —ç—Ç–æ–º —Ä–µ—Å—Ç–æ—Ä–∞–Ω–µ. –•–æ–¥–∏–º ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>–ú–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è —ç—Ç–æ—Ç —Ä–µ—Å—Ç–æ—Ä–∞–Ω, –±—ã–ª–∞ —Ç–∞–º –¥–≤–∞–∂–¥—ã –∏,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>–°–µ–º–µ–π–Ω–æ–µ —Ç–æ—Ä–∂–µ—Å—Ç–≤–æ –æ—Ç–º–µ—á–∞–ª–∏ –≤ –ê–º–∞–¥–µ—É—Å–µ 30 –º–∞—è ...</td>\n",
       "      <td>None</td>\n",
       "      <td>positive</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>–ü—Ä–∏—à–ª–∏ –≤ –¥–∞–Ω–Ω–æ–µ –∑–∞–≤–µ–¥–µ–Ω–∏–µ 4 –∏—é–Ω—è 2014 –≥–æ–¥–∞ –ø–æ–∫...</td>\n",
       "      <td>None</td>\n",
       "      <td>positive</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>–î–∞–≤–Ω–æ —Ö–æ—Ç–µ–ª–∏ —Å—Ö–æ–¥–∏—Ç—å –≤ —ç—Ç–æ –∫–∞—Ñ–µ(—Ç–µ–º –±–æ–ª–µ–µ –∂–∏–≤–µ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3539 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_text food_sentiment   \n",
       "0     Judging from previous posts this used to be a ...       negative  \\\n",
       "1     I have eaten at Saul, many times, the food is ...       positive   \n",
       "2     Went on a 3 day oyster binge, with Fish bringi...       positive   \n",
       "3     Every time in New York I make it a point to vi...       positive   \n",
       "4     We ate outside at Haru's Sake bar because Haru...       positive   \n",
       "...                                                 ...            ...   \n",
       "3534  –ë—ã–ª–∏ –≤—á–µ—Ä–∞ —Å –ø–æ–¥—Ä—É–≥–æ–π –≤ —ç—Ç–æ–º —Ä–µ—Å—Ç–æ—Ä–∞–Ω–µ. –•–æ–¥–∏–º ...           None   \n",
       "3535  –ú–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è —ç—Ç–æ—Ç —Ä–µ—Å—Ç–æ—Ä–∞–Ω, –±—ã–ª–∞ —Ç–∞–º –¥–≤–∞–∂–¥—ã –∏,...           None   \n",
       "3536  –°–µ–º–µ–π–Ω–æ–µ —Ç–æ—Ä–∂–µ—Å—Ç–≤–æ –æ—Ç–º–µ—á–∞–ª–∏ –≤ –ê–º–∞–¥–µ—É—Å–µ 30 –º–∞—è ...           None   \n",
       "3537  –ü—Ä–∏—à–ª–∏ –≤ –¥–∞–Ω–Ω–æ–µ –∑–∞–≤–µ–¥–µ–Ω–∏–µ 4 –∏—é–Ω—è 2014 –≥–æ–¥–∞ –ø–æ–∫...           None   \n",
       "3538  –î–∞–≤–Ω–æ —Ö–æ—Ç–µ–ª–∏ —Å—Ö–æ–¥–∏—Ç—å –≤ —ç—Ç–æ –∫–∞—Ñ–µ(—Ç–µ–º –±–æ–ª–µ–µ –∂–∏–≤–µ...           None   \n",
       "\n",
       "     service_sentiment atmosphere_sentiment  \n",
       "0             negative                 None  \n",
       "1                 None                 None  \n",
       "2             positive                 None  \n",
       "3             positive             positive  \n",
       "4             positive                 None  \n",
       "...                ...                  ...  \n",
       "3534              None                 None  \n",
       "3535              None             positive  \n",
       "3536          positive                 None  \n",
       "3537          positive                 None  \n",
       "3538              None                 None  \n",
       "\n",
       "[3539 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xmltodict\n",
    "\n",
    "\n",
    "semval_df = pd.DataFrame(columns=['review_text','food_sentiment','service_sentiment', 'atmosphere_sentiment'])\n",
    "\n",
    "\n",
    "for file in ['ABSA16_Restaurants_Train_English_SB2.xml', 'restaurants_dutch_training_textlevel.xml', 'restaurant_tain_text_level_final.xml', 'SemEval-2016ABSA Restaurants-Spanish_Train_Subtask2.xml', 'se16_ru_rest_train_task2.xml']:\n",
    "    with open(f'data/semeval/{file}') as f:\n",
    "       xml_string = f.read()\n",
    "    print(file)\n",
    "    xml_dict = xmltodict.parse(xml_string)\n",
    "    Reviews = xml_dict['Reviews']['Review']\n",
    "    for review in Reviews:\n",
    "        sentence_concat = ''\n",
    "        #print(review)\n",
    "        if isinstance(review['sentences']['sentence'], dict):\n",
    "            sentence_concat += review['sentences']['sentence']['text'] + \" \"\n",
    "        else:\n",
    "            for sentence in review['sentences']['sentence']:\n",
    "                #print(sentence)\n",
    "                sentence_concat += sentence['text'] + \" \"\n",
    "        sent_food = None\n",
    "        sent_service = None\n",
    "        sent_atmosphere = None\n",
    "        #print('review:', review)\n",
    "        if (review['Opinions'] != None):\n",
    "            if isinstance(review['Opinions']['Opinion'], dict):\n",
    "                opinion = review['Opinions']['Opinion']\n",
    "                if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                    sent_food = opinion['@polarity']\n",
    "                elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                    sent_service = opinion['@polarity']\n",
    "                elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                    sent_atmosphere = opinion['@polarity']\n",
    "            else:\n",
    "                for opinion in review['Opinions']['Opinion']:\n",
    "                    if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                        sent_food = opinion['@polarity']\n",
    "                    elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                        sent_service = opinion['@polarity']\n",
    "                    elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                        sent_atmosphere = opinion['@polarity']\n",
    "        semval_df.loc[len(semval_df)] = [sentence_concat, sent_food, sent_service, sent_atmosphere]\n",
    "print(semval_df)\n",
    "\n",
    "\n",
    "for file in ['ABSA16_Restaurants_Train_SB1_v2.xml', 'restaurants_dutch_training.xml', 'reviews.xml', 'SemEval-2016ABSA Restaurants-Spanish_Train_Subtask1.xml', 'se16_ru_rest_train.xml']:\n",
    "    with open(f'data/semeval/{file}') as f:\n",
    "       xml_string = f.read()\n",
    "    print(file)\n",
    "    xml_dict = xmltodict.parse(xml_string)\n",
    "    Reviews = xml_dict['Reviews']['Review']\n",
    "    for review in Reviews:\n",
    "        sentence_concat = ''\n",
    "        if isinstance(review['sentences']['sentence'], dict):\n",
    "            sentence_concat += review['sentences']['sentence']['text'] + \" \"\n",
    "        else:\n",
    "            for sentence in review['sentences']['sentence']:\n",
    "                sentence_concat += sentence['text'] + \" \"\n",
    "                sent_food = None\n",
    "                sent_service = None\n",
    "                sent_atmosphere = None\n",
    "                if ('Opinions' in sentence) and (sentence['Opinions'] != None):\n",
    "                    if isinstance(sentence['Opinions']['Opinion'], dict):\n",
    "                        opinion = sentence['Opinions']['Opinion']\n",
    "                        if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                            sent_food = opinion['@polarity']\n",
    "                        elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                            sent_service = opinion['@polarity']\n",
    "                        elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                            sent_atmosphere = opinion['@polarity']\n",
    "                    else:\n",
    "                        for opinion in sentence['Opinions']['Opinion']:\n",
    "                            if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                                sent_food = opinion['@polarity']\n",
    "                            elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                                sent_service = opinion['@polarity']\n",
    "                            elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                                sent_atmosphere = opinion['@polarity']\n",
    "            semval_df.loc[len(semval_df)] = [sentence_concat, sent_food, sent_service, sent_atmosphere]\n",
    "semval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f81a68ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_sentiment\n",
      "None        1722\n",
      "positive    1370\n",
      "negative     275\n",
      "neutral       88\n",
      "conflict      84\n",
      "Name: count, dtype: int64\n",
      "service_sentiment\n",
      "None        2007\n",
      "positive     961\n",
      "negative     458\n",
      "conflict      65\n",
      "neutral       48\n",
      "Name: count, dtype: int64\n",
      "atmosphere_sentiment\n",
      "None        2402\n",
      "positive     831\n",
      "negative     192\n",
      "conflict      71\n",
      "neutral       43\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(semval_df['food_sentiment'].value_counts(dropna=False))\n",
    "print(semval_df['service_sentiment'].value_counts(dropna=False))\n",
    "print(semval_df['atmosphere_sentiment'].value_counts(dropna=False))\n",
    "\n",
    "#print(list(semval_df[semval_df.ambiance_sentiment == 'conflict'].review_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "103c2e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN_REST_SB2_TEST.xml.gold\n",
      "DU_REST_SB2_TEST.xml.gold\n",
      "RU_REST_SB2_TEST.xml.gold\n",
      "SP_REST_SB2_TEST.xml.gold\n",
      "TU_REST_SB2_TEST.xml.gold\n",
      "<bound method DataFrame.info of                                            review_text food_sentiment   \n",
      "0    Yum! Serves really good sushi. Not the biggest...       positive  \\\n",
      "1    No Comparison ‚Äì I can't say enough about this ...       positive   \n",
      "2    Snotty Attitude ‚Äì We were treated very rudely ...           None   \n",
      "3    Good food! ‚Äì We love breakfast food. This is a...       positive   \n",
      "4    Overrated ‚Äì I was highly disappointed in the f...       negative   \n",
      "..                                                 ...            ...   \n",
      "595  Kebap ve Et restoranlarƒ± aleminde sƒ±k√ßa kar≈üƒ±l...       positive   \n",
      "596  Manzara s√ºper,yemekler fena deƒüil ama porsiyon...        neutral   \n",
      "597  √ßok sƒ±cak √ßok kalabalƒ±k denizden koku geliyor ...       negative   \n",
      "598  √áalƒ±≈üanlar kesinlikle √ßok nezih. √áayƒ± da g√ºzel...       positive   \n",
      "599  Deniz kenarƒ±nda olan b√ºt√ºn mekanlarƒ±n aurasƒ± b...       positive   \n",
      "\n",
      "    service_sentiment atmosphere_sentiment  \n",
      "0                None                 None  \n",
      "1            positive                 None  \n",
      "2            negative                 None  \n",
      "3            positive                 None  \n",
      "4                None             positive  \n",
      "..                ...                  ...  \n",
      "595              None             positive  \n",
      "596              None             positive  \n",
      "597          negative             negative  \n",
      "598          positive                 None  \n",
      "599              None             positive  \n",
      "\n",
      "[600 rows x 4 columns]>\n",
      "EN_REST_SB1_TEST.xml.gold\n",
      "DU_REST_SB1_TEST.xml.gold\n",
      "ABSA16FR_Restaurants_Gold-withcontent.xml\n",
      "RU_REST_SB1_TEST.xml.gold\n",
      "SP_REST_SB1_TEST.xml.gold\n",
      "TU_REST_SB1_TEST.xml.gold\n",
      "                                            review_text food_sentiment   \n",
      "0     Yum! Serves really good sushi. Not the biggest...       positive  \\\n",
      "1     No Comparison ‚Äì I can't say enough about this ...       positive   \n",
      "2     Snotty Attitude ‚Äì We were treated very rudely ...           None   \n",
      "3     Good food! ‚Äì We love breakfast food. This is a...       positive   \n",
      "4     Overrated ‚Äì I was highly disappointed in the f...       negative   \n",
      "...                                                 ...            ...   \n",
      "1241  S√ºtl√º tatlilari m√ºkemmel diyebilirim. √áayi g√ºz...           None   \n",
      "1242  Kebap ve Et restoranlarƒ± aleminde sƒ±k√ßa kar≈üƒ±l...           None   \n",
      "1243  Manzara s√ºper,yemekler fena deƒüil ama porsiyon...           None   \n",
      "1244  √áalƒ±≈üanlar kesinlikle √ßok nezih. √áayƒ± da g√ºzel...           None   \n",
      "1245  Deniz kenarƒ±nda olan b√ºt√ºn mekanlarƒ±n aurasƒ± b...       positive   \n",
      "\n",
      "     service_sentiment atmosphere_sentiment  \n",
      "0                 None                 None  \n",
      "1             positive                 None  \n",
      "2             negative                 None  \n",
      "3             positive                 None  \n",
      "4                 None             positive  \n",
      "...                ...                  ...  \n",
      "1241              None             negative  \n",
      "1242              None             positive  \n",
      "1243              None                 None  \n",
      "1244              None                 None  \n",
      "1245              None                 None  \n",
      "\n",
      "[1246 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "\n",
    "import xmltodict\n",
    "\n",
    "\n",
    "semval_test_df = pd.DataFrame(columns=['review_text','food_sentiment','service_sentiment', 'atmosphere_sentiment'])\n",
    "\n",
    "for file in ['EN_REST_SB2_TEST.xml.gold', 'DU_REST_SB2_TEST.xml.gold', 'RU_REST_SB2_TEST.xml.gold', 'SP_REST_SB2_TEST.xml.gold', 'TU_REST_SB2_TEST.xml.gold']:\n",
    "    with open(f'data/semeval/test/{file}') as f:\n",
    "       xml_string = f.read()\n",
    "    print(file)\n",
    "    xml_dict = xmltodict.parse(xml_string)\n",
    "    Reviews = xml_dict['Reviews']['Review']\n",
    "    for review in Reviews:\n",
    "        sentence_concat = ''\n",
    "        if isinstance(review['sentences']['sentence'], dict):\n",
    "            sentence_concat += review['sentences']['sentence']['text'] + \" \"\n",
    "        else:\n",
    "            for sentence in review['sentences']['sentence']:\n",
    "                sentence_concat += sentence['text'] + \" \"\n",
    "        sent_food = None\n",
    "        sent_service = None\n",
    "        sent_atmosphere = None\n",
    "        if (review['Opinions'] != None):\n",
    "            if isinstance(review['Opinions']['Opinion'], dict):\n",
    "                opinion = review['Opinions']['Opinion']\n",
    "                if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                    sent_food = opinion['@polarity']\n",
    "                elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                    sent_service = opinion['@polarity']\n",
    "                elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                    sent_atmosphere = opinion['@polarity']\n",
    "            else:\n",
    "                for opinion in review['Opinions']['Opinion']:\n",
    "                    if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                        sent_food = opinion['@polarity']\n",
    "                    elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                        sent_service = opinion['@polarity']\n",
    "                    elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                        sent_atmosphere = opinion['@polarity']\n",
    "        semval_test_df.loc[len(semval_test_df)] = [sentence_concat, sent_food, sent_service, sent_atmosphere]\n",
    "print(semval_test_df.info)\n",
    "\n",
    "for file in ['EN_REST_SB1_TEST.xml.gold', 'DU_REST_SB1_TEST.xml.gold', 'ABSA16FR_Restaurants_Gold-withcontent.xml', 'RU_REST_SB1_TEST.xml.gold', 'SP_REST_SB1_TEST.xml.gold', 'TU_REST_SB1_TEST.xml.gold']:\n",
    "    with open(f'data/semeval/test/{file}') as f:\n",
    "       xml_string = f.read()\n",
    "    print(file)\n",
    "    xml_dict = xmltodict.parse(xml_string)\n",
    "    Reviews = xml_dict['Reviews']['Review']\n",
    "    for review in Reviews:\n",
    "        sentence_concat = ''\n",
    "        if isinstance(review['sentences']['sentence'], dict):\n",
    "            sentence_concat += review['sentences']['sentence']['text'] + \" \"\n",
    "        else:\n",
    "            for sentence in review['sentences']['sentence']:\n",
    "                if sentence['text'] != None:\n",
    "                    sentence_concat += sentence['text'] + \" \"\n",
    "                    sent_food = None\n",
    "                    sent_service = None\n",
    "                    sent_atmosphere = None\n",
    "                    if ('Opinions' in sentence) and (sentence['Opinions'] != None):\n",
    "                        if isinstance(sentence['Opinions']['Opinion'], dict):\n",
    "                            opinion = sentence['Opinions']['Opinion']\n",
    "                            if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                                sent_food = opinion['@polarity']\n",
    "                            elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                                sent_service = opinion['@polarity']\n",
    "                            elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                                sent_atmosphere = opinion['@polarity']\n",
    "                        else:\n",
    "                            for opinion in sentence['Opinions']['Opinion']:\n",
    "                                if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                                    sent_food = opinion['@polarity']\n",
    "                                elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                                    sent_service = opinion['@polarity']\n",
    "                                elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                                    sent_atmosphere = opinion['@polarity']\n",
    "            semval_test_df.loc[len(semval_test_df)] = [sentence_concat, sent_food, sent_service, sent_atmosphere]\n",
    "print(semval_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "370de286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_sentiment\n",
      "None        657\n",
      "positive    453\n",
      "negative     81\n",
      "conflict     30\n",
      "neutral      25\n",
      "Name: count, dtype: int64\n",
      "service_sentiment\n",
      "None        748\n",
      "positive    333\n",
      "negative    133\n",
      "conflict     17\n",
      "neutral      15\n",
      "Name: count, dtype: int64\n",
      "atmosphere_sentiment\n",
      "None        907\n",
      "positive    234\n",
      "negative     69\n",
      "conflict     24\n",
      "neutral      12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(semval_test_df['food_sentiment'].value_counts(dropna=False))\n",
    "print(semval_test_df['service_sentiment'].value_counts(dropna=False))\n",
    "print(semval_test_df['atmosphere_sentiment'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b05fe41",
   "metadata": {},
   "source": [
    "## Attempt 1: LLM API Zero-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a27ae0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter API key for Google Gemini: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "02d9bf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sehr leckeres Essen... Personal ist zudem sehr freundlich. [('food_sentiment', 0.9), ('service_sentiment', 0.8), ('atmoshphere_sentiment', None)]\n",
      "Auf 800 m auf der Sonnenterrasse Heiden treffen sich Schweiz und eine ausgezeichnete libanesische K√ºche: Die Speisen sind sehr lecker, die Bedienung freundlich und entgegenkommend und man f√ºhlt sich sofort willkommen! Unser Ausflug hat sich gelohnt! [('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmosphere_sentiment', 1.0)]\n",
      "Sehr feines Libanesisches Essen. Ein Hauch vom Orient mitten in Appenzell. Definitiv ein Besuch wert. [('food_sentiment', 0.9), ('service_sentiment', None), ('atmoshphere_sentiment', 0.8)]\n",
      "Gutes Essen [('food_sentiment', 0.8), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n",
      "Toller Geheimtipp.\n",
      "Nicht viel Platz daf√ºr eine umso professionellere Bedienung.\n",
      "Das Essen ist super und sch√∂n angerichtet. [('food_sentiment', 0.95), ('service_sentiment', 0.95), ('atmoshphere_sentiment', -0.3)]\n",
      "Great food and nice friendly familiar service. [('food_sentiment', 0.9), ('service_sentiment', 0.8), ('atmoshphere_sentiment', None)]\n",
      "Einfach mega lecker. Ich komme gerne wieder! [('food_sentiment', 1.0), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n",
      "absolut top! Wunderbares authentisches Essen, herzlicher Service, tolle Beratung und eine sch√∂ne Einrichtung. Wir kommen gerne wieder! [('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmoshphere_sentiment', 0.9)]\n",
      "\"**Ein absolutes Highlight f√ºr Liebhaber der libanesischen K√ºche!**\n",
      "\n",
      "Das Essen in diesem Restaurant ist einfach unglaublich lecker. Jedes Gericht ist eine wahre Geschmacksexplosion und man merkt, dass hier nur frische, hochwertige Zutaten verwendet werden und mit viel Liebe und Hingabe gekocht wird.\n",
      "Besonders beeindruckt hat mich die grosse Auswahl an veganen Gerichten, die mit genauso viel Liebe und Kreativit√§t zubereitet werden wie der Rest der Speisekarte.\n",
      "\n",
      "Der Besitzer ist √§usserst freundlich und nimmt sich Zeit, die einzelnen Gerichte ausf√ºhrlich zu erkl√§ren. Diese pers√∂nliche Note und die herzliche Atmosph√§re machen den Besuch zu einem rundum angenehmen Erlebnis. Man f√ºhlt sich sofort willkommen und gut aufgehoben.\n",
      "\n",
      "Ich kann dieses Restaurant w√§rmstens empfehlen ‚Äì egal ob f√ºr Fleischliebhaber oder Veganer, hier wird jeder f√ºndig und begeistert sein!\"\n",
      "\n",
      "Danke f√ºr dieses rundum gelungene Essenserlebnis! :) [('food_sentiment', 1.0), ('service_sentiment', 1.0), ('atmoshphere_sentiment', 0.9)]\n",
      "Sehr gute K√ºche. Gen√ºgend Zeit nehmen und geniessen. [('food_sentiment', 0.9), ('service_sentiment', None), ('atmoshphere_sentiment', None)]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "text = \"Please perform Aspect-Based Sentiment Classification task on google maps reviews. \\\n",
    "Given a review, classify each (sentiment, rating) pair. \\\n",
    "Sentiments are ['food_sentiment', 'service_sentiment', 'atmoshphere_sentiment']. \\\n",
    "'food_sentiment' should answer: What does the review say about how good the food was? \\\n",
    "'service_sentiment' should answer: What does the review say about how good the service was? \\\n",
    "'atmosphere_sentiment' should answer: What does the review say about how good the atmoshpere was? \\\n",
    "Ratings should be selected as a floating point number from -1 to 1. Where 1 means excellent, above all expectations, and -1 means the worst ever experienced. \\\n",
    "If a sentiment does not apply, its rating should be the python Value 'None'. \\\n",
    "This also applies to short reviews like 'Great!'.\\\n",
    "Always return a valid python list of tuples containing a string in single quotes and a float for each sentiment.\\\n",
    "Please return python list only, without any other comments or texts.\"\n",
    "\n",
    "#output2 = []\n",
    "#for sentence in sentences.review.to_list()[::-1]:\n",
    "#    messages = [\n",
    "#        SystemMessage(content=text),\n",
    "#        HumanMessage(content=sentence),\n",
    "#    ]\n",
    "#    output2.append(model.invoke(messages).content)\n",
    "#    print(sentence, output2[-1])\n",
    "\n",
    "output = []\n",
    "for sentence in gold_df.review.to_list():\n",
    "    messages = [\n",
    "        SystemMessage(content=text),\n",
    "        HumanMessage(content=sentence),\n",
    "    ]\n",
    "    output.append(model.invoke(messages).content)\n",
    "    print(sentence, output[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c54d1014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m new_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m \u001b[43moutput\u001b[49m:\n\u001b[1;32m      4\u001b[0m     new_list\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28meval\u001b[39m(el)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28meval\u001b[39m(el)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28meval\u001b[39m(el)[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m      5\u001b[0m array_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(new_list, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "new_list = []\n",
    "for el in output:\n",
    "    new_list.append([eval(el)[0][1], eval(el)[1][1], eval(el)[2][1]])\n",
    "array_list = np.array(new_list, dtype=float)\n",
    "array_gold = gold_df[['food_sentiment', 'service_sentiment','atmoshpere_sentiment']].to_numpy()\n",
    "print(array_list, array_gold)\n",
    "print(type(array_gold[0][1]))\n",
    "array_gold[np.isnan(array_gold)] = 0\n",
    "array_list[np.isnan(array_list)] = 0\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(array_gold, array_list)\n",
    "\n",
    "# TODO: \n",
    "# - Also get the semeval test data\n",
    "# - Manually compute MSE on non-None datapoints\n",
    "# - seperate evaluation for None-prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db2fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b424e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b08393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ad6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 1 example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928fafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output shape and output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94166d75",
   "metadata": {},
   "source": [
    "## Version 2: Sentence Transformer + Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9141234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/miniconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/miniconda3/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <1DA7CD7A-B394-3FDC-A22B-2C5432CB870C> /opt/miniconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <B6BD92AE-4D03-3F92-9E03-2E2594A12866> /opt/miniconda3/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05180492  0.0234477   0.00977761 ...  0.02363102 -0.04960595\n",
      "  -0.02839927]\n",
      " [-0.0643362  -0.00336044 -0.07328292 ...  0.03205855 -0.00261604\n",
      "  -0.00922436]\n",
      " [-0.05540531 -0.00983528 -0.04669202 ...  0.02031407 -0.00767633\n",
      "  -0.03695137]\n",
      " ...\n",
      " [-0.00785295 -0.0202017  -0.04557296 ...  0.01872295 -0.00336646\n",
      "   0.00022772]\n",
      " [ 0.00712993 -0.03182698 -0.0520607  ... -0.03922683 -0.04274593\n",
      "  -0.04744959]\n",
      " [-0.01753766  0.01300661 -0.0251427  ...  0.01437551 -0.00632532\n",
      "  -0.01388594]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/LaBSE', token='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')\n",
    "embeddings = model.encode(semval_df.review_text.to_list())\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71273c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3539, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86a344c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "y_food = semval_df.food_sentiment.to_list()\n",
    "y_service = semval_df.service_sentiment.to_list()\n",
    "y_atmosphere = semval_df.atmosphere_sentiment.to_list()\n",
    "y_none = zip(y_food, y_service, y_atmosphere)\n",
    "\n",
    "def map_values(x):\n",
    "    if x == 'positive':\n",
    "        return 1\n",
    "    elif x == 'negative':\n",
    "        return -1\n",
    "    elif x == 'neutral':\n",
    "        return 0\n",
    "    elif x == 'conflict':\n",
    "        return 0\n",
    "    elif x == None:\n",
    "        return 0\n",
    "    else:\n",
    "        raise Exception(\"an error occurred\")\n",
    "    \n",
    "y_food = list(map(map_values, y_food))\n",
    "y_service = list(map(map_values, y_service))\n",
    "y_atmosphere = list(map(map_values, y_atmosphere))\n",
    "\n",
    "def map_none(x):\n",
    "    if x == None:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "y_none = [list(map(map_none, el)) for el in y_none]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1e8e736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n",
      "0\n",
      "[0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_food[0])\n",
    "print(y_service[0])\n",
    "print(y_atmosphere[0])\n",
    "print(y_none[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf7236d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.289304030637572\n",
      "0.2779766010692323\n",
      "0.22183844833765018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'none_array = clf.predict(X_test)\\nmse = 0\\nnum = 0\\nnum_none = 0\\ncorrect_none = 0\\narray_y = list(zip(y_test_food, y_test_service, y_test_atmosphere))\\nfor i in range(len(array_y)):\\n    for j in range(len(array_y[i])):\\n        el = array_y[i][j]\\n        if not np.isnan(el):\\n            mse += (el - array_y[i][j])**2\\n            num += 1\\n            if none_array[i][j] == 0:\\n                correct_none += 1\\n        else:\\n            if none_array[i][j] == 1:\\n                correct_none += 1\\n        num_none += 1\\nprint(\"custom mse:\", mse/num)\\nprint(\"none_accuracy:\", correct_none/num_none)\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    embeddings, list(zip(y_food, y_service, y_atmosphere, y_none)), test_size=0.33, random_state=42)\n",
    "y_train_food, y_train_service, y_train_atmosphere, y_train_none = zip(*y_train)\n",
    "y_test_food, y_test_service, y_test_atmosphere, y_test_none = zip(*y_test)\n",
    "\n",
    "reg_food = MLPRegressor(random_state=1, max_iter=2000, tol=0.1).fit(X_train, y_train_food)\n",
    "reg_service = MLPRegressor(random_state=1, max_iter=2000, tol=0.1).fit(X_train, y_train_service)\n",
    "reg_atmosphere = MLPRegressor(random_state=1, max_iter=2000, tol=0.1).fit(X_train, y_train_atmosphere)\n",
    "y_pred_food = reg_food.predict(X_test)\n",
    "print(mean_squared_error(y_test_food, y_pred_food))\n",
    "y_pred_service = reg_service.predict(X_test)\n",
    "print(mean_squared_error(y_test_service, y_pred_service))\n",
    "y_pred_atmosphere = reg_atmosphere.predict(X_test)\n",
    "print(mean_squared_error(y_test_atmosphere, y_pred_atmosphere))\n",
    "\n",
    "\n",
    "array_pred = list(zip(reg_food.predict(X_test), \n",
    "                      reg_service.predict(X_test), \n",
    "                      reg_atmosphere.predict(X_test)))\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = MLPClassifier(random_state=1, hidden_layer_sizes=(100,100), max_iter=300).fit(X_train, y_train_none)\n",
    "\n",
    "\"\"\"none_array = clf.predict(X_test)\n",
    "mse = 0\n",
    "num = 0\n",
    "num_none = 0\n",
    "correct_none = 0\n",
    "array_y = list(zip(y_test_food, y_test_service, y_test_atmosphere))\n",
    "for i in range(len(array_y)):\n",
    "    for j in range(len(array_y[i])):\n",
    "        el = array_y[i][j]\n",
    "        if not np.isnan(el):\n",
    "            mse += (el - array_y[i][j])**2\n",
    "            num += 1\n",
    "            if none_array[i][j] == 0:\n",
    "                correct_none += 1\n",
    "        else:\n",
    "            if none_array[i][j] == 1:\n",
    "                correct_none += 1\n",
    "        num_none += 1\n",
    "print(\"custom mse:\", mse/num)\n",
    "print(\"none_accuracy:\", correct_none/num_none)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c1f4335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom mse: 0.059267871324329355\n",
      "none_accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "array_gold = gold_df[['food_sentiment', 'service_sentiment','atmoshpere_sentiment']].to_numpy()\n",
    "#print(array_gold)\n",
    "embeddings_gold = model.encode(gold_df.review.to_list())\n",
    "#print(embeddings_gold)\n",
    "\n",
    "#print(reg_food.predict(embeddings_gold))\n",
    "#print(reg_service.predict(embeddings_gold))\n",
    "#print(reg_atmosphere.predict(embeddings_gold))\n",
    "#print(clf.predict(embeddings_gold))\n",
    "\n",
    "array_pred = list(zip(reg_food.predict(embeddings_gold), \n",
    "                      reg_service.predict(embeddings_gold), \n",
    "                      reg_atmosphere.predict(embeddings_gold)))\n",
    "mse = 0\n",
    "num = 0\n",
    "num_none = 0\n",
    "correct_none = 0\n",
    "none_array = clf.predict(embeddings_gold)\n",
    "for i in range(len(array_gold)):\n",
    "    for j in range(len(array_gold[i])):\n",
    "        el = array_gold[i][j]\n",
    "        if not np.isnan(el):\n",
    "            mse += (el - array_pred[i][j])**2\n",
    "            num += 1\n",
    "            if none_array[i][j] == 0:\n",
    "                correct_none += 1\n",
    "        else:\n",
    "            if none_array[i][j] == 1:\n",
    "                correct_none += 1\n",
    "        num_none += 1\n",
    "print(\"custom mse:\", mse/num)\n",
    "print(\"none_accuracy:\", correct_none/num_none)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b80499",
   "metadata": {},
   "source": [
    "## Version 3: NLP Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11990640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a806a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b292612",
   "metadata": {},
   "source": [
    "### Appendix 1: Failed local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "029c5c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "What is the capital of France.<|im_end|>\n",
      "\n",
      "<|im_start|>user\n",
      "What is the capital of France.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The capital of France is Paris, officially known as the City of Light. It is the seat of the French government, the national capital, and the capital of the √éle-de-France region.\n",
      "\n",
      "Paris is\n"
     ]
    }
   ],
   "source": [
    "# pip install transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "checkpoint = \"HuggingFaceTB/SmolLM-360M-Instruct\"\n",
    "\n",
    "device = \"cpu\" # for GPU usage or \"cpu\" for CPU usage\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, token='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')\n",
    "# for multiple GPUs install accelerate and do `model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\")`\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, token='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').to(device)\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is the capital of France.\"}]\n",
    "input_text=tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "print(input_text)\n",
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs, max_new_tokens=50, temperature=0.2, top_p=0.9, do_sample=True)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48870ec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease perform Aspect-Based Sentiment Classification task on google maps reviews. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mGiven a review, classify each (sentiment, rating) pair. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mSentiments are [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_food\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_ambiance\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_service\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124mstring in single quotes and a float for each sentiment. Please return python list only, \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mwithout any other comments or texts.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m output2 \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m \u001b[43msentences\u001b[49m\u001b[38;5;241m.\u001b[39mreview\u001b[38;5;241m.\u001b[39mto_list()[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     11\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:text},\n\u001b[1;32m     13\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:sentence},\n\u001b[1;32m     14\u001b[0m     ]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#messages = [{\"role\": \"user\", \"content\": \"What is the capital of France.\"}]\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentences' is not defined"
     ]
    }
   ],
   "source": [
    "text = \"Please perform Aspect-Based Sentiment Classification task on google maps reviews. \\\n",
    "Given a review, classify each (sentiment, rating) pair. \\\n",
    "Sentiments are ['sentiment_food', 'sentiment_ambiance', 'sentiment_service'] \\\n",
    ", and ratings should be selected as a floating point number from -1 to 1. \\\n",
    "If a sentiment does not apply, its rating should be 0. This also applies to short reviews like 'Great!'\\\n",
    "Always return a valid python list of tuples containing a \\\n",
    "string in single quotes and a float for each sentiment. Please return python list only, \\\n",
    "without any other comments or texts.\"\n",
    "output2 = []\n",
    "for sentence in sentences.review.to_list()[::-1]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\":text},\n",
    "        {\"role\": \"user\", \"content\":sentence},\n",
    "    ]\n",
    "#messages = [{\"role\": \"user\", \"content\": \"What is the capital of France.\"}]\n",
    "    input_text=tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    #print(input_text)\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(inputs, max_new_tokens=50, temperature=0.2, top_p=0.9, do_sample=False)\n",
    "    print('output:', tokenizer.decode(outputs[0]))\n",
    "\n",
    "#output2.append(model.invoke(messages).content)\n",
    "#print(sentence, output2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d3457dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have eaten at Saul, many times, the food is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Went on a 3 day oyster binge, with Fish bringi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Every time in New York I make it a point to vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We ate outside at Haru's Sake bar because Haru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>This small Astoria souvlaki spot makes what ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>I was here a few weeks back and we had the wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>After passing by this restaurant for sometime ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Having hunted around for a quiet, romantic, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Suan is a great place that I often take my fri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews\n",
       "0    Judging from previous posts this used to be a ...\n",
       "1    I have eaten at Saul, many times, the food is ...\n",
       "2    Went on a 3 day oyster binge, with Fish bringi...\n",
       "3    Every time in New York I make it a point to vi...\n",
       "4    We ate outside at Haru's Sake bar because Haru...\n",
       "..                                                 ...\n",
       "330  This small Astoria souvlaki spot makes what ma...\n",
       "331  I was here a few weeks back and we had the wor...\n",
       "332  After passing by this restaurant for sometime ...\n",
       "333  Having hunted around for a quiet, romantic, ye...\n",
       "334  Suan is a great place that I often take my fri...\n",
       "\n",
       "[335 rows x 1 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "semval_data = pd.DataFrame()\n",
    "\n",
    "tree = ET.parse('data/semeval/ABSA16_Restaurants_Train_English_SB2.xml')\n",
    "root = tree.getroot()\n",
    " \n",
    "reviews = []\n",
    "for review in root.findall('Review'):\n",
    "    for sentences in review.findall('sentences'):\n",
    "        full_review = ''\n",
    "        for sentence in sentences.findall('sentence'):\n",
    "            full_review += sentence.find('text').text.replace(\"\\'\", \"'\") + ' '\n",
    "    #print(full_review)\n",
    "    reviews.append(full_review)\n",
    "    for Opinions in review.find('Opinions'):\n",
    "        for opinion in Opinions.findall('Opinion'):\n",
    "            print(opinion.find('category'))\n",
    "        break\n",
    "semval_data['reviews'] = reviews\n",
    "semval_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
