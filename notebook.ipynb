{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0150c5f",
   "metadata": {},
   "source": [
    "# Cohaga DS Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da765fe",
   "metadata": {},
   "source": [
    "## Data import and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4001df41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a99c99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of       google_maps_profile_id  review_id   \n",
      "0                     624932    6386691  \\\n",
      "1                     624932    6386692   \n",
      "2                     624932    6386693   \n",
      "3                     624932    6386694   \n",
      "4                     624932    6386695   \n",
      "...                      ...        ...   \n",
      "9995                  151741    3027281   \n",
      "9996                  151741    3027284   \n",
      "9997                  151741    3027288   \n",
      "9998                  151741    3027291   \n",
      "9999                  151741    3027293   \n",
      "\n",
      "                                                 review  rating   \n",
      "0     Sehr leckeres Essen... Personal ist zudem sehr...       5  \\\n",
      "1     Auf 800 m auf der Sonnenterrasse Heiden treffe...       5   \n",
      "2     Sehr feines Libanesisches Essen. Ein Hauch vom...       5   \n",
      "3                                           Gutes Essen       5   \n",
      "4     Toller Geheimtipp.\\nNicht viel Platz daf√ºr ein...       5   \n",
      "...                                                 ...     ...   \n",
      "9995  Pas assez d'intimit√© quand on est seul sinon m...       3   \n",
      "9996  Accueil tres bien\\nService souriant\\nTres prop...       5   \n",
      "9997  La cuisine d'Alain Meystre est toujours aussi ...       5   \n",
      "9998  Nous √©tions c√¥te brasserie,pour un  menu surpr...       5   \n",
      "9999             Tr√®s bon accueil et tr√®s bonne cuisine       4   \n",
      "\n",
      "                                             source_url  \n",
      "0     https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "1     https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "2     https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "3     https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "4     https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "...                                                 ...  \n",
      "9995  https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "9996  https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "9997  https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "9998  https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "9999  https://www.google.com/maps/reviews/data=!4m8!...  \n",
      "\n",
      "[10000 rows x 5 columns]>\n",
      "[RangeIndex(start=0, stop=10000, step=1), Index(['google_maps_profile_id', 'review_id', 'review', 'rating',\n",
      "       'source_url'],\n",
      "      dtype='object')]\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"data/task_1_google_maps_comments.csv\")\n",
    "print(data_df.info)\n",
    "print(data_df.axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd85efba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   google_maps_profile_id  10000 non-null  int64 \n",
      " 1   review                  10000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "sentences = data_df.loc[:, ['google_maps_profile_id', 'review']]\n",
    "sentences.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b114ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Add review length analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e832c41",
   "metadata": {},
   "source": [
    "###¬†Check languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42faeb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "model = fasttext.load_model('models/lid.176.bin')\n",
    "lang_list = [model.predict(review.replace('\\n', ' '), k=1)[0][0] for review in sentences.review]\n",
    "sentences['language'] = lang_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1e2de99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__label__eo', '__label__ms', '__label__zh', '__label__fa', '__label__cs', '__label__ko', '__label__de', '__label__hu', '__label__nl', '__label__it', '__label__pl', '__label__sh', '__label__ceb', '__label__en', '__label__bg', '__label__sl', '__label__he', '__label__fr', '__label__ro', '__label__tr', '__label__nds', '__label__br', '__label__vi', '__label__ia', '__label__id', '__label__eu', '__label__sv', '__label__ja', '__label__mn', '__label__fi', '__label__la', '__label__sk', '__label__nn', '__label__ar', '__label__ru', '__label__pt', '__label__hr', '__label__sr', '__label__ast', '__label__bn', '__label__es', '__label__da', '__label__th', '__label__als', '__label__el', '__label__oc', '__label__ca', '__label__no', '__label__gl', '__label__uk'}\n",
      "__label__eo Paradiso puro\n",
      "__label__ms Guter Kebap\n",
      "__label__zh üòÄüòÄüòÄ\n",
      "__label__fa ÿÆŸàÿ® ÿ®ŸàÿØ\n",
      "__label__cs V≈°e bylo v√Ωborn√©\n",
      "__label__ko ÏïÑÎ¶ÑÎã§Ïö¥Í≤ΩÏπòÏóêÏÑúÏ∞®ÌïúÏûî\n",
      "__label__de Sehr leckeres Essen... Personal ist zudem sehr freundlich.\n",
      "__label__hu Sz√©p hangulatos helyen, finom √©telek. Maxim√°lis vend√©gl√°t√°s.\n",
      "__label__nl Top!\n",
      "__label__it Panorama stupendo, servizio cortese e professionale . La cucina √® curata e i piatti appagano l'occhio e la gola!!!!! Ci ritorner√≤ quanto prima!!!\n",
      "__label__pl Cudny widok, pyszne szwajcarskie piwko i winko\n",
      "__label__sh Tip top\n",
      "__label__ceb üòÄüòÑüòÑüòÑ\n",
      "__label__en Great food and nice friendly familiar service.\n",
      "__label__bg –í–∫—É—Å–Ω–æ.\n",
      "__label__sl Guet gsiii\n",
      "__label__he ◊û◊ß◊ï◊ù ◊û◊¢◊ï◊ú◊î ◊ú◊¢◊¶◊ô◊®◊î ◊û◊ï◊ú ◊†◊ï◊£ ◊û◊ò◊ï◊®◊£.\n",
      "__label__fr Sehr lecker\n",
      "__label__ro Patronul foarte rau\n",
      "__label__tr Cok basarili keyifli lezzetli manzarasi harika bir restorant g√ºlery√ºzl√º servis\n",
      "__label__nds Sehr leckeres Essen!üòÄ‚ù§Ô∏è\n",
      "__label__br zebra burger>\n",
      "__label__vi Un saluto a Giov√† :D\n",
      "__label__ia A repetir a visita! ‚ù§Ô∏è‚úåÔ∏è‚úåÔ∏è\n",
      "__label__id Tiptop\n",
      "__label__eu S beste vo de w√§lt üòòüòç\n",
      "__label__sv üëå\n",
      "__label__ja „Çπ„Éç„Ç¨„Åã„ÇâÊ≠©„ÅÑ„Å¶ÂæÄÂæ©„Åó„Åæ„Åó„Åü„Åå„ÄÅÂùÇ„Åå„Å®„Çì„Åß„ÇÇ„Å™„Åè„Åç„Å§„Åã„Å£„Åü„Åß„ÅôÁ¨ë„ÄÄ„Éì„Éº„É´„ÅØ6CHFüòä„ÄÄÊ∏ÖÊΩî„ÅßÈõ∞Âõ≤Ê∞ó„ÅåËâØ„ÅÑÁ¥†Êïµ„Å™„É¨„Çπ„Éà„É©„É≥„Åß„Åó„ÅüÔºÅ\n",
      "__label__mn Super . –°–∞–π—Ö–∞–Ω –º—ç–¥—Ä—ç–º–∂ “Ø—Ö—Ä–∏–π–Ω –º–∞—Ö –∞–¥—É—É–Ω—ã –º–∞—Ö –∑–∞–≥–∞—Å –±“Ø–≥–¥ –æ—Ä—á–∏–Ω —Å–∞–π—Ö–∞–Ω —É—Ä–ª–∞–≥–∏–π–Ω –±“Ø—Ç—ç—ç–ª “Ø—Ö—ç—Ä –º–∞–Ω–¥—Ç—É–≥–∞–π\n",
      "__label__fi Terassi mahtavien vuorten vieress√§ ja palvelu great!!üòÄ\n",
      "__label__la Tiptoppüëåüòç\n",
      "__label__sk Pekn√° miestna re≈°taur√°cia v alpskom ≈°t√Ωle. Pizza super.Ceny samozrejme na √∫rovni ≈°vajƒçiarskych √Ålp üòÅüòÅ\n",
      "__label__nn Perfekt üëçüëçüëç\n",
      "__label__ar ŸÖŸÉÿßŸÜ Ÿäÿ≥ÿ™ÿ≠ŸÇ ÿßŸÑÿ≤Ÿäÿßÿ±ÿ© ÿßŸÑŸÖŸàŸÇÿπ ŸÖŸÇÿßÿ®ŸÑ ÿßŸÑÿ®ÿ≠Ÿäÿ±ÿ©\n",
      "__label__ru –í–∏–¥ —Å —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞, –∑–∞–≤–æ—Ä–∞–∂–∏–≤–∞–µ—Ç. –ö—É—Ö–Ω—è —Ç–æ–∂–µ –æ—Ç–ª–∏—á–Ω–∞—è, —à–≤–µ–π—Ü–∞—Ä—Å–∫–∞—è.\n",
      "–¶–µ–Ω—ã —Ç–∞–∫ –∂–µ, –Ω–µ —Å–∞–º—ã–µ –±–æ–ª—å—à–∏–µ –≤ –®–≤–µ–π—Ü–∞—Ä–∏–∏.\n",
      "__label__pt Atendimento impec√°vel e excelente variedade de comida libanesa.\n",
      "__label__hr Sasvim pristojno. Omjer cijene i kvalitete.\n",
      "__label__sr Izuzetno ƒçisto, izuzetno ljubazno osoblje, izuzetno sve≈æa i ukusna hrana, domaƒáinski u pravom smislu te reƒçi.\n",
      "Lidija Stefanoviƒá, Waltenschwil\n",
      "__label__ast Wunderbares Ostermen√ºe.\n",
      "__label__bn Mega fein gsi\n",
      "__label__es Muy recomendable üëå üëç\n",
      "__label__da Hyggelig after ski med flott beliggenhet. Akkurat n√•r du kommer ned fra en mega-lang nedkj√∏ling fra fjellet og bena er passe gele. Da er det godt med en √∏l üòä\n",
      "__label__th ‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏Å‡∏≤‡∏®‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏° ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢‡∏°‡∏≤‡∏Å‡πÜ‡πÜ‡πÜ\n",
      "__label__als Dank√§ viilmal f√ºr dii fr√º√ºndlich bedienig... Esch sch√∂n gsi bi √∂ui üòè\n",
      "__label__el ŒïŒØŒΩŒ±Œπ œÑŒ≠ŒªŒµŒπŒø. üòç\n",
      "__label__oc Mmmmmh...\n",
      "__label__ca Vistes impressionants. Bon menjar i bon servei\n",
      "__label__no Placut\n",
      "__label__gl Genial:)\n",
      "__label__uk –°–º–∞—á–Ω–æ, —à–≤–∏–¥–∫–æ, –ø—Ä–∏–≤—ñ—Ç–Ω–æ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "language\n",
       "__label__de     5808\n",
       "__label__en     1728\n",
       "__label__fr      991\n",
       "__label__it      951\n",
       "__label__es       99\n",
       "__label__nl       62\n",
       "__label__pt       52\n",
       "__label__ar       51\n",
       "__label__pl       29\n",
       "__label__tr       24\n",
       "__label__als      22\n",
       "__label__ko       20\n",
       "__label__sv       17\n",
       "__label__ru       16\n",
       "__label__zh       15\n",
       "__label__ja       14\n",
       "__label__hu        8\n",
       "__label__da        7\n",
       "__label__cs        6\n",
       "__label__fi        6\n",
       "__label__ro        6\n",
       "__label__sl        5\n",
       "__label__ca        5\n",
       "__label__ceb       5\n",
       "__label__no        5\n",
       "__label__vi        4\n",
       "__label__bg        4\n",
       "__label__id        4\n",
       "__label__uk        3\n",
       "__label__eo        3\n",
       "__label__he        3\n",
       "__label__hr        3\n",
       "__label__sr        2\n",
       "__label__oc        2\n",
       "__label__th        2\n",
       "__label__ms        2\n",
       "__label__el        2\n",
       "__label__sk        2\n",
       "__label__fa        1\n",
       "__label__br        1\n",
       "__label__ast       1\n",
       "__label__nds       1\n",
       "__label__gl        1\n",
       "__label__mn        1\n",
       "__label__nn        1\n",
       "__label__eu        1\n",
       "__label__la        1\n",
       "__label__ia        1\n",
       "__label__bn        1\n",
       "__label__sh        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(set(lang_list))\n",
    "for l in set(lang_list):\n",
    "    print(l, sentences[sentences.language == l].iloc[0].review)\n",
    "sentences.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207df52f",
   "metadata": {},
   "source": [
    "### Public Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "002c902c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Judging from previous posts this used to be a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have eaten at Saul, many times, the food is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Went on a 3 day oyster binge, with Fish bringi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Every time in New York I make it a point to vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We ate outside at Haru's Sake bar because Haru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>This small Astoria souvlaki spot makes what ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>I was here a few weeks back and we had the wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>After passing by this restaurant for sometime ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Having hunted around for a quiet, romantic, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Suan is a great place that I often take my fri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews\n",
       "0    Judging from previous posts this used to be a ...\n",
       "1    I have eaten at Saul, many times, the food is ...\n",
       "2    Went on a 3 day oyster binge, with Fish bringi...\n",
       "3    Every time in New York I make it a point to vi...\n",
       "4    We ate outside at Haru's Sake bar because Haru...\n",
       "..                                                 ...\n",
       "330  This small Astoria souvlaki spot makes what ma...\n",
       "331  I was here a few weeks back and we had the wor...\n",
       "332  After passing by this restaurant for sometime ...\n",
       "333  Having hunted around for a quiet, romantic, ye...\n",
       "334  Suan is a great place that I often take my fri...\n",
       "\n",
       "[335 rows x 1 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "semval_data = pd.DataFrame()\n",
    "\n",
    "tree = ET.parse('data/semeval/ABSA16_Restaurants_Train_English_SB2.xml')\n",
    "root = tree.getroot()\n",
    " \n",
    "reviews = []\n",
    "for review in root.findall('Review'):\n",
    "    for sentences in review.findall('sentences'):\n",
    "        full_review = ''\n",
    "        for sentence in sentences.findall('sentence'):\n",
    "            full_review += sentence.find('text').text.replace(\"\\'\", \"'\") + ' '\n",
    "    #print(full_review)\n",
    "    reviews.append(full_review)\n",
    "    for Opinions in review.find('Opinions'):\n",
    "        for opinion in Opinions.findall('Opinion'):\n",
    "            print(opinion.find('category'))\n",
    "        break\n",
    "semval_data['reviews'] = reviews\n",
    "semval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2e9d3de3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSA16_Restaurants_Train_English_SB2.xml\n",
      "restaurants_dutch_training_textlevel.xml\n",
      "restaurant_tain_text_level_final.xml\n",
      "SemEval-2016ABSA Restaurants-Spanish_Train_Subtask2.xml\n",
      "se16_ru_rest_train_task2.xml\n",
      "                                            review_text food_sentiment   \n",
      "0     Judging from previous posts this used to be a ...       negative  \\\n",
      "1     I have eaten at Saul, many times, the food is ...       positive   \n",
      "2     Went on a 3 day oyster binge, with Fish bringi...       positive   \n",
      "3     Every time in New York I make it a point to vi...       positive   \n",
      "4     We ate outside at Haru's Sake bar because Haru...       positive   \n",
      "...                                                 ...            ...   \n",
      "1859  –°–µ–≥–æ–¥–Ω—è –±—ã–ª–∏ –∫–æ–º–ø–∞–Ω–∏–µ–π –∏–∑ 4—Ö —á–µ–ª–æ–≤–µ–∫, –±—ã–ª–∏ —É–∂–µ...       positive   \n",
      "1860  –í—á–µ—Ä–∞ –æ—Ç–º–µ—á–∞–ª–∏ –¥–µ–Ω—å —Ä–æ–∂–¥–µ–Ω–∏—è –≤ —Ä–µ—Å—Ç–æ—Ä–∞–Ω–µ, —Å—Ö–æ–¥...       positive   \n",
      "1861  –û—á–µ–Ω—å –ø—Ä–∏—è—Ç–Ω–æ–µ —É—é—Ç–Ω–æ–µ –º–µ—Å—Ç–µ—á–∫–æ. –•–æ—Ä–æ—à–∏–π —Ü–µ–Ω–Ω–∏–∫...       conflict   \n",
      "1862  –í –ø—Ä–æ—à–ª—É—é —Å—É–±–±–æ—Ç—É –ø–æ—Å–µ—Ç–∏–ª–∏ —Å –¥—Ä—É–∑—å—è–º–∏ —ç—Ç–æ –∑–∞–≤–µ...       positive   \n",
      "1863  –ó–∞—à–ª–∏ –≤\"–∞–ø–ø–µ—Ç–∏—Ç\" —Å–ª—É—á–∞–π–Ω–æ. –ù–µ —Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ,—á—Ç–æ...       positive   \n",
      "\n",
      "     ambiance_sentiment service_sentiment  \n",
      "0               neutral          negative  \n",
      "1               neutral           neutral  \n",
      "2               neutral          positive  \n",
      "3              positive          positive  \n",
      "4               neutral          positive  \n",
      "...                 ...               ...  \n",
      "1859           conflict          positive  \n",
      "1860           positive          positive  \n",
      "1861           conflict          conflict  \n",
      "1862           conflict          positive  \n",
      "1863            neutral          positive  \n",
      "\n",
      "[1864 rows x 4 columns]\n",
      "ABSA16_Restaurants_Train_SB1_v2.xml\n",
      "restaurants_dutch_training.xml\n",
      "reviews.xml\n",
      "SemEval-2016ABSA Restaurants-Spanish_Train_Subtask1.xml\n",
      "se16_ru_rest_train.xml\n",
      "<bound method DataFrame.info of                                             review_text food_sentiment   \n",
      "0     Judging from previous posts this used to be a ...       negative  \\\n",
      "1     I have eaten at Saul, many times, the food is ...       positive   \n",
      "2     Went on a 3 day oyster binge, with Fish bringi...       positive   \n",
      "3     Every time in New York I make it a point to vi...       positive   \n",
      "4     We ate outside at Haru's Sake bar because Haru...       positive   \n",
      "...                                                 ...            ...   \n",
      "3534  –ë—ã–ª–∏ –≤—á–µ—Ä–∞ —Å –ø–æ–¥—Ä—É–≥–æ–π –≤ —ç—Ç–æ–º —Ä–µ—Å—Ç–æ—Ä–∞–Ω–µ. –•–æ–¥–∏–º ...        neutral   \n",
      "3535  –ú–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è —ç—Ç–æ—Ç —Ä–µ—Å—Ç–æ—Ä–∞–Ω, –±—ã–ª–∞ —Ç–∞–º –¥–≤–∞–∂–¥—ã –∏,...        neutral   \n",
      "3536  –°–µ–º–µ–π–Ω–æ–µ —Ç–æ—Ä–∂–µ—Å—Ç–≤–æ –æ—Ç–º–µ—á–∞–ª–∏ –≤ –ê–º–∞–¥–µ—É—Å–µ 30 –º–∞—è ...        neutral   \n",
      "3537  –ü—Ä–∏—à–ª–∏ –≤ –¥–∞–Ω–Ω–æ–µ –∑–∞–≤–µ–¥–µ–Ω–∏–µ 4 –∏—é–Ω—è 2014 –≥–æ–¥–∞ –ø–æ–∫...        neutral   \n",
      "3538  –î–∞–≤–Ω–æ —Ö–æ—Ç–µ–ª–∏ —Å—Ö–æ–¥–∏—Ç—å –≤ —ç—Ç–æ –∫–∞—Ñ–µ(—Ç–µ–º –±–æ–ª–µ–µ –∂–∏–≤–µ...        neutral   \n",
      "\n",
      "     ambiance_sentiment service_sentiment  \n",
      "0               neutral          negative  \n",
      "1               neutral           neutral  \n",
      "2               neutral          positive  \n",
      "3              positive          positive  \n",
      "4               neutral          positive  \n",
      "...                 ...               ...  \n",
      "3534            neutral           neutral  \n",
      "3535            neutral           neutral  \n",
      "3536            neutral           neutral  \n",
      "3537            neutral           neutral  \n",
      "3538            neutral           neutral  \n",
      "\n",
      "[3539 rows x 4 columns]>\n"
     ]
    }
   ],
   "source": [
    "import xmltodict\n",
    "\n",
    "\n",
    "semval_df = pd.DataFrame(columns=['review_text','food_sentiment','ambiance_sentiment','service_sentiment'])\n",
    "\n",
    "\n",
    "for file in ['ABSA16_Restaurants_Train_English_SB2.xml', 'restaurants_dutch_training_textlevel.xml', 'restaurant_tain_text_level_final.xml', 'SemEval-2016ABSA Restaurants-Spanish_Train_Subtask2.xml', 'se16_ru_rest_train_task2.xml']:\n",
    "    with open(f'data/semeval/{file}') as f:\n",
    "       xml_string = f.read()\n",
    "    print(file)\n",
    "    xml_dict = xmltodict.parse(xml_string)\n",
    "    Reviews = xml_dict['Reviews']['Review']\n",
    "    for review in Reviews:\n",
    "        sentence_concat = ''\n",
    "        #print(review)\n",
    "        if isinstance(review['sentences']['sentence'], dict):\n",
    "            sentence_concat += review['sentences']['sentence']['text'] + \" \"\n",
    "        else:\n",
    "            for sentence in review['sentences']['sentence']:\n",
    "                #print(sentence)\n",
    "                sentence_concat += sentence['text'] + \" \"\n",
    "        sent_food = 'neutral'\n",
    "        sent_ambiance = 'neutral'\n",
    "        sent_service = 'neutral'\n",
    "        #print('review:', review)\n",
    "        if (review['Opinions'] != None):\n",
    "            if isinstance(review['Opinions']['Opinion'], dict):\n",
    "                opinion = review['Opinions']['Opinion']\n",
    "                if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                    sent_food = opinion['@polarity']\n",
    "                elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                    sent_service = opinion['@polarity']\n",
    "                elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                    sent_ambiance = opinion['@polarity']\n",
    "            else:\n",
    "                for opinion in review['Opinions']['Opinion']:\n",
    "                    if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                        sent_food = opinion['@polarity']\n",
    "                    elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                        sent_service = opinion['@polarity']\n",
    "                    elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                        sent_ambiance = opinion['@polarity']\n",
    "        semval_df.loc[len(semval_df)] = [sentence_concat, sent_food, sent_ambiance, sent_service]\n",
    "print(semval_df)\n",
    "\n",
    "\n",
    "for file in ['ABSA16_Restaurants_Train_SB1_v2.xml', 'restaurants_dutch_training.xml', 'reviews.xml', 'SemEval-2016ABSA Restaurants-Spanish_Train_Subtask1.xml', 'se16_ru_rest_train.xml']:\n",
    "    with open(f'data/semeval/{file}') as f:\n",
    "       xml_string = f.read()\n",
    "    print(file)\n",
    "    xml_dict = xmltodict.parse(xml_string)\n",
    "    Reviews = xml_dict['Reviews']['Review']\n",
    "    for review in Reviews:\n",
    "        #print(review['sentences']['sentence'])\n",
    "        sentence_concat = ''\n",
    "        #print(review)\n",
    "        if isinstance(review['sentences']['sentence'], dict):\n",
    "            sentence_concat += review['sentences']['sentence']['text'] + \" \"\n",
    "        else:\n",
    "            #print(review['sentences']['sentence'])\n",
    "            for sentence in review['sentences']['sentence']:\n",
    "                #print(sentence)\n",
    "                sentence_concat += sentence['text'] + \" \"\n",
    "                sent_food = 'neutral'\n",
    "                sent_ambiance = 'neutral'\n",
    "                sent_service = 'neutral'\n",
    "                #print('review:', review)\n",
    "                if (Opinions in sentence) and (sentence['Opinions'] != None):\n",
    "                    if isinstance(sentence['Opinions']['Opinion'], dict):\n",
    "                        opinion = sentence['Opinions']['Opinion']\n",
    "                        if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                            sent_food = opinion['@polarity']\n",
    "                        elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                            sent_service = opinion['@polarity']\n",
    "                        elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                            sent_ambiance = opinion['@polarity']\n",
    "                    else:\n",
    "                        for opinion in sentence['Opinions']['Opinion']:\n",
    "                            if 'FOOD#QUALITY' in opinion['@category']:\n",
    "                                sent_food = opinion['@polarity']\n",
    "                            elif 'SERVICE#GENERAL' in opinion['@category']:\n",
    "                                sent_service = opinion['@polarity']\n",
    "                            elif 'AMBIENCE#GENERAL' in opinion['@category']:\n",
    "                                sent_ambiance = opinion['@polarity']\n",
    "            semval_df.loc[len(semval_df)] = [sentence_concat, sent_food, sent_ambiance, sent_service]\n",
    "print(semval_df.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "41322e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_sentiment\n",
      "neutral     2081\n",
      "positive    1151\n",
      "negative     223\n",
      "conflict      84\n",
      "Name: count, dtype: int64\n",
      "ambiance_sentiment\n",
      "neutral     2620\n",
      "positive     705\n",
      "negative     143\n",
      "conflict      71\n",
      "Name: count, dtype: int64\n",
      "service_sentiment\n",
      "neutral     2298\n",
      "positive     825\n",
      "negative     351\n",
      "conflict      65\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(semval_df['food_sentiment'].value_counts())\n",
    "print(semval_df['ambiance_sentiment'].value_counts())\n",
    "print(semval_df['service_sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28a6f16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                 category  polarity\n",
       "0     RESTAURANT#GENERAL  negative\n",
       "1        SERVICE#GENERAL  negative\n",
       "2           FOOD#QUALITY  negative\n",
       "3     FOOD#STYLE_OPTIONS  negative\n",
       "4           FOOD#QUALITY  positive\n",
       "...                  ...       ...\n",
       "1430    LOCATION#GENERAL  positive\n",
       "1431   RESTAURANT#PRICES  positive\n",
       "1432        FOOD#QUALITY  positive\n",
       "1433    AMBIENCE#GENERAL  positive\n",
       "1434     SERVICE#GENERAL  positive\n",
       "\n",
       "[1435 rows x 2 columns]>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_xml('data/semeval/ABSA16_Restaurants_Train_English_SB2.xml', xpath=\".//Opinion\")\n",
    "test.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9125994c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b05fe41",
   "metadata": {},
   "source": [
    "## Attempt 1: LLM API Zero-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a27ae0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter API key for Google Gemini: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d9bf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tr√®s bon accueil et tr√®s bonne cuisine [('sentiment_food', 1.0), ('sentiment_ambiance', 0.0), ('sentiment_service', 1.0)]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "text = \"Please perform Aspect-Based Sentiment Classification task on google maps reviews. \\\n",
    "Given a review, classify each (sentiment, rating) pair. \\\n",
    "Sentiments are ['sentiment_food', 'sentiment_ambiance', 'sentiment_service'], \\\n",
    "and ratings should be selected as a floating point number from -1 to 1. \\\n",
    "If a sentiment does not apply, its rating should be 0. \\\n",
    "This also applies to short reviews like 'Great!'.\\\n",
    "Always return a valid python list of tuples containing a string in single quotes and a float for each sentiment.\\\n",
    "Please return python list only, without any other comments or texts.\"\n",
    "\n",
    "output2 = []\n",
    "for sentence in sentences.review.to_list()[::-1]:\n",
    "    messages = [\n",
    "        SystemMessage(content=text),\n",
    "        HumanMessage(content=sentence),\n",
    "    ]\n",
    "    output2.append(model.invoke(messages).content)\n",
    "    print(sentence, output2[-1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c54d1014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"[('sentiment_food', 1.0), ('sentiment_ambiance', 0.0), ('sentiment_service', 1.0)]\"]\n"
     ]
    }
   ],
   "source": [
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3051d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Tr√®s bon accueil et tr√®s bonne cuisine', \"[('sentiment_food', 1.0), ('sentiment_ambiance', 0.0), ('sentiment_service', 1.0)]\")]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(sentences.review.to_list()[-1:], output2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b424e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b08393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ad6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 1 example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928fafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output shape and output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94166d75",
   "metadata": {},
   "source": [
    "## Version 2: Sentence Transformer + Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141234a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a806a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fa96ee9",
   "metadata": {},
   "source": [
    "### Appendix 1: Failed local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "029c5c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "What is the capital of France.<|im_end|>\n",
      "\n",
      "<|im_start|>user\n",
      "What is the capital of France.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The capital of France is Paris, officially known as the City of Light. It is the seat of the French government, the national capital, and the capital of the √éle-de-France region.\n",
      "\n",
      "Paris is\n"
     ]
    }
   ],
   "source": [
    "# pip install transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "checkpoint = \"HuggingFaceTB/SmolLM-360M-Instruct\"\n",
    "\n",
    "device = \"cpu\" # for GPU usage or \"cpu\" for CPU usage\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, token='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')\n",
    "# for multiple GPUs install accelerate and do `model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=\"auto\")`\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, token='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').to(device)\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is the capital of France.\"}]\n",
    "input_text=tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "print(input_text)\n",
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs, max_new_tokens=50, temperature=0.2, top_p=0.9, do_sample=True)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48870ec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease perform Aspect-Based Sentiment Classification task on google maps reviews. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mGiven a review, classify each (sentiment, rating) pair. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mSentiments are [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_food\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_ambiance\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_service\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124mstring in single quotes and a float for each sentiment. Please return python list only, \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mwithout any other comments or texts.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m output2 \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m \u001b[43msentences\u001b[49m\u001b[38;5;241m.\u001b[39mreview\u001b[38;5;241m.\u001b[39mto_list()[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     11\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:text},\n\u001b[1;32m     13\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:sentence},\n\u001b[1;32m     14\u001b[0m     ]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#messages = [{\"role\": \"user\", \"content\": \"What is the capital of France.\"}]\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentences' is not defined"
     ]
    }
   ],
   "source": [
    "text = \"Please perform Aspect-Based Sentiment Classification task on google maps reviews. \\\n",
    "Given a review, classify each (sentiment, rating) pair. \\\n",
    "Sentiments are ['sentiment_food', 'sentiment_ambiance', 'sentiment_service'] \\\n",
    ", and ratings should be selected as a floating point number from -1 to 1. \\\n",
    "If a sentiment does not apply, its rating should be 0. This also applies to short reviews like 'Great!'\\\n",
    "Always return a valid python list of tuples containing a \\\n",
    "string in single quotes and a float for each sentiment. Please return python list only, \\\n",
    "without any other comments or texts.\"\n",
    "output2 = []\n",
    "for sentence in sentences.review.to_list()[::-1]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\":text},\n",
    "        {\"role\": \"user\", \"content\":sentence},\n",
    "    ]\n",
    "#messages = [{\"role\": \"user\", \"content\": \"What is the capital of France.\"}]\n",
    "    input_text=tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    #print(input_text)\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(inputs, max_new_tokens=50, temperature=0.2, top_p=0.9, do_sample=False)\n",
    "    print('output:', tokenizer.decode(outputs[0]))\n",
    "\n",
    "#output2.append(model.invoke(messages).content)\n",
    "#print(sentence, output2[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
